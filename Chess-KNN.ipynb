{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%config InlineBackend.figure_format = 'retina'\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>wking_file_a</th>\n",
       "      <th>wking_file_b</th>\n",
       "      <th>wking_file_c</th>\n",
       "      <th>wking_file_d</th>\n",
       "      <th>wking_rank_1</th>\n",
       "      <th>wking_rank_2</th>\n",
       "      <th>wking_rank_3</th>\n",
       "      <th>wking_rank_4</th>\n",
       "      <th>wrook_file_a</th>\n",
       "      <th>wrook_file_b</th>\n",
       "      <th>...</th>\n",
       "      <th>bking_file_h</th>\n",
       "      <th>bking_rank_1</th>\n",
       "      <th>bking_rank_2</th>\n",
       "      <th>bking_rank_3</th>\n",
       "      <th>bking_rank_4</th>\n",
       "      <th>bking_rank_5</th>\n",
       "      <th>bking_rank_6</th>\n",
       "      <th>bking_rank_7</th>\n",
       "      <th>bking_rank_8</th>\n",
       "      <th>Y</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 41 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   wking_file_a  wking_file_b  wking_file_c  wking_file_d  wking_rank_1  \\\n",
       "0             1             0             0             0             1   \n",
       "1             1             0             0             0             1   \n",
       "2             1             0             0             0             1   \n",
       "3             1             0             0             0             1   \n",
       "4             1             0             0             0             1   \n",
       "\n",
       "   wking_rank_2  wking_rank_3  wking_rank_4  wrook_file_a  wrook_file_b ...  \\\n",
       "0             0             0             0             0             1 ...   \n",
       "1             0             0             0             0             0 ...   \n",
       "2             0             0             0             0             0 ...   \n",
       "3             0             0             0             0             0 ...   \n",
       "4             0             0             0             0             0 ...   \n",
       "\n",
       "   bking_file_h  bking_rank_1  bking_rank_2  bking_rank_3  bking_rank_4  \\\n",
       "0             0             0             1             0             0   \n",
       "1             0             0             1             0             0   \n",
       "2             0             1             0             0             0   \n",
       "3             0             0             1             0             0   \n",
       "4             0             1             0             0             0   \n",
       "\n",
       "   bking_rank_5  bking_rank_6  bking_rank_7  bking_rank_8  Y  \n",
       "0             0             0             0             0  0  \n",
       "1             0             0             0             0  0  \n",
       "2             0             0             0             0  0  \n",
       "3             0             0             0             0  0  \n",
       "4             0             0             0             0  0  \n",
       "\n",
       "[5 rows x 41 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chess_oh = pd.read_csv('chess_oh.csv')\n",
    "chess_oh.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create 5 trials, each with train and test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "XY_train1, XY_test1 = train_test_split(chess_oh, train_size=5000, shuffle=True)\n",
    "XY_train2, XY_test2 = train_test_split(chess_oh, train_size=5000, shuffle=True)\n",
    "XY_train3, XY_test3 = train_test_split(chess_oh, train_size=5000, shuffle=True)\n",
    "XY_train4, XY_test4 = train_test_split(chess_oh, train_size=5000, shuffle=True)\n",
    "XY_train5, XY_test5 = train_test_split(chess_oh, train_size=5000, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5000, 41)\n",
      "(23056, 41)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>wking_file_a</th>\n",
       "      <th>wking_file_b</th>\n",
       "      <th>wking_file_c</th>\n",
       "      <th>wking_file_d</th>\n",
       "      <th>wking_rank_1</th>\n",
       "      <th>wking_rank_2</th>\n",
       "      <th>wking_rank_3</th>\n",
       "      <th>wking_rank_4</th>\n",
       "      <th>wrook_file_a</th>\n",
       "      <th>wrook_file_b</th>\n",
       "      <th>...</th>\n",
       "      <th>bking_file_h</th>\n",
       "      <th>bking_rank_1</th>\n",
       "      <th>bking_rank_2</th>\n",
       "      <th>bking_rank_3</th>\n",
       "      <th>bking_rank_4</th>\n",
       "      <th>bking_rank_5</th>\n",
       "      <th>bking_rank_6</th>\n",
       "      <th>bking_rank_7</th>\n",
       "      <th>bking_rank_8</th>\n",
       "      <th>Y</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>22252</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>272</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12616</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1650</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11974</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 41 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       wking_file_a  wking_file_b  wking_file_c  wking_file_d  wking_rank_1  \\\n",
       "22252             0             0             1             0             1   \n",
       "272               0             1             0             0             1   \n",
       "12616             0             1             0             0             1   \n",
       "1650              0             0             0             1             1   \n",
       "11974             1             0             0             0             1   \n",
       "\n",
       "       wking_rank_2  wking_rank_3  wking_rank_4  wrook_file_a  wrook_file_b  \\\n",
       "22252             0             0             0             0             0   \n",
       "272               0             0             0             0             0   \n",
       "12616             0             0             0             0             0   \n",
       "1650              0             0             0             1             0   \n",
       "11974             0             0             0             0             0   \n",
       "\n",
       "      ...  bking_file_h  bking_rank_1  bking_rank_2  bking_rank_3  \\\n",
       "22252 ...             1             0             0             0   \n",
       "272   ...             0             0             0             1   \n",
       "12616 ...             0             0             0             0   \n",
       "1650  ...             0             0             0             0   \n",
       "11974 ...             0             0             0             0   \n",
       "\n",
       "       bking_rank_4  bking_rank_5  bking_rank_6  bking_rank_7  bking_rank_8  Y  \n",
       "22252             0             0             0             0             1  1  \n",
       "272               0             0             0             0             0  0  \n",
       "12616             0             0             0             1             0  0  \n",
       "1650              0             0             0             0             1  0  \n",
       "11974             0             1             0             0             0  0  \n",
       "\n",
       "[5 rows x 41 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(XY_train1.shape)\n",
    "print(XY_test1.shape)\n",
    "XY_train1.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Perform GridSearchCV on classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------------------------------------------------------\n",
      "RESULTS FOR TRIAL:\n",
      "1\n",
      "------------------------------------------------------------------------------------\n",
      "---------------BEST MODEL FOR ACCURACY: ----------\n",
      "{'metric': 'manhattan', 'n_neighbors': 11, 'weights': 'distance'}\n",
      "---WITH ACCURACY: ---\n",
      "0.8522000000000001\n",
      "---------------BEST MODEL FOR ROC: ---------------\n",
      "{'metric': 'manhattan', 'n_neighbors': 19, 'weights': 'distance'}\n",
      "---WITH ROC: ---\n",
      "0.9278945365199214\n",
      "---------------BEST MODEL FOR F1: ----------------\n",
      "{'metric': 'manhattan', 'n_neighbors': 11, 'weights': 'distance'}\n",
      "---WITH F1: ---\n",
      "0.8522000000000001\n",
      "------------------------------------------------------------------------------------\n",
      "RESULTS FOR TRIAL:\n",
      "2\n",
      "------------------------------------------------------------------------------------\n",
      "---------------BEST MODEL FOR ACCURACY: ----------\n",
      "{'metric': 'manhattan', 'n_neighbors': 19, 'weights': 'distance'}\n",
      "---WITH ACCURACY: ---\n",
      "0.8503999999999999\n",
      "---------------BEST MODEL FOR ROC: ---------------\n",
      "{'metric': 'manhattan', 'n_neighbors': 19, 'weights': 'distance'}\n",
      "---WITH ROC: ---\n",
      "0.9295282440075336\n",
      "---------------BEST MODEL FOR F1: ----------------\n",
      "{'metric': 'manhattan', 'n_neighbors': 19, 'weights': 'distance'}\n",
      "---WITH F1: ---\n",
      "0.8503999999999999\n",
      "------------------------------------------------------------------------------------\n",
      "RESULTS FOR TRIAL:\n",
      "3\n",
      "------------------------------------------------------------------------------------\n",
      "---------------BEST MODEL FOR ACCURACY: ----------\n",
      "{'metric': 'manhattan', 'n_neighbors': 11, 'weights': 'distance'}\n",
      "---WITH ACCURACY: ---\n",
      "0.842\n",
      "---------------BEST MODEL FOR ROC: ---------------\n",
      "{'metric': 'manhattan', 'n_neighbors': 19, 'weights': 'distance'}\n",
      "---WITH ROC: ---\n",
      "0.9224028208840467\n",
      "---------------BEST MODEL FOR F1: ----------------\n",
      "{'metric': 'manhattan', 'n_neighbors': 11, 'weights': 'distance'}\n",
      "---WITH F1: ---\n",
      "0.842\n",
      "------------------------------------------------------------------------------------\n",
      "RESULTS FOR TRIAL:\n",
      "4\n",
      "------------------------------------------------------------------------------------\n",
      "---------------BEST MODEL FOR ACCURACY: ----------\n",
      "{'metric': 'manhattan', 'n_neighbors': 19, 'weights': 'distance'}\n",
      "---WITH ACCURACY: ---\n",
      "0.8486\n",
      "---------------BEST MODEL FOR ROC: ---------------\n",
      "{'metric': 'manhattan', 'n_neighbors': 19, 'weights': 'distance'}\n",
      "---WITH ROC: ---\n",
      "0.929108595836999\n",
      "---------------BEST MODEL FOR F1: ----------------\n",
      "{'metric': 'manhattan', 'n_neighbors': 19, 'weights': 'distance'}\n",
      "---WITH F1: ---\n",
      "0.8486\n",
      "------------------------------------------------------------------------------------\n",
      "RESULTS FOR TRIAL:\n",
      "5\n",
      "------------------------------------------------------------------------------------\n",
      "---------------BEST MODEL FOR ACCURACY: ----------\n",
      "{'metric': 'manhattan', 'n_neighbors': 11, 'weights': 'distance'}\n",
      "---WITH ACCURACY: ---\n",
      "0.85\n",
      "---------------BEST MODEL FOR ROC: ---------------\n",
      "{'metric': 'manhattan', 'n_neighbors': 19, 'weights': 'distance'}\n",
      "---WITH ROC: ---\n",
      "0.9280155579543168\n",
      "---------------BEST MODEL FOR F1: ----------------\n",
      "{'metric': 'manhattan', 'n_neighbors': 11, 'weights': 'distance'}\n",
      "---WITH F1: ---\n",
      "0.85\n",
      "Wall time: 1min 2s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "#import warnings\n",
    "# there are a lot of convergence warnings for some params, however be careful with this!!\n",
    "# sometimes you need to see those wanrings, and now we've screwed tha tup for the whole notebook from here on!!\n",
    "#warnings.filterwarnings('ignore')\n",
    "\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn import datasets\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "import numpy as np\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "# Create a pipeline - RF is a stand in, we will populate the classifier part below\n",
    "pipe = Pipeline([('std', StandardScaler()),\n",
    "                 ('classifier', KNeighborsClassifier())])\n",
    "\n",
    "# Create search space of candidate learning algorithms and their hyperparameters\n",
    "grid_params = {\n",
    "    'n_neighbors': [3,5,11,19],\n",
    "    'weights': ['uniform', 'distance'],\n",
    "    'metric': ['euclidean', 'manhattan']\n",
    "}\n",
    "\n",
    "trialnum = 0\n",
    "accuracy_sum = 0 # sum of top accuracy to later calculate the average of all 5 trials\n",
    "roc_sum = 0 # sum of top roc score to later calculate the average of all 5 trials\n",
    "f1_sum = 0 # sum of top accuracy to later calculate the average of all 5 trials\n",
    "accuracy_scores = []\n",
    "roc_scores = []\n",
    "f1_scores = []\n",
    "all_accuracy_models = []\n",
    "all_roc_models = []\n",
    "all_f1_models = []\n",
    "\n",
    "# for every trial\n",
    "for trial in [XY_train1, XY_train2, XY_train3, XY_train4, XY_train5]:\n",
    " \n",
    "    trialnum = trialnum + 1\n",
    "    X_l = trial.drop(['Y'],1)\n",
    "    y_l = trial['Y']\n",
    "\n",
    "    clf = GridSearchCV(KNeighborsClassifier(), param_grid=grid_params, cv=StratifiedKFold(n_splits=5), \n",
    "                      scoring=['accuracy', 'roc_auc_ovr', 'f1_micro'], refit=False, \n",
    "                       n_jobs=-1, verbose=-1)\n",
    "\n",
    "    # Fit grid search\n",
    "    best_model = clf.fit(X_l, y_l)\n",
    "    \n",
    "    print(\"------------------------------------------------------------------------------------\")\n",
    "    print(\"RESULTS FOR TRIAL:\")\n",
    "    print(trialnum)\n",
    "    print(\"------------------------------------------------------------------------------------\")\n",
    "    \n",
    "    # the detailed results of the whole model selection search...\n",
    "#     print(best_model.cv_results_)\n",
    "\n",
    "    print(\"---------------BEST MODEL FOR ACCURACY: ----------\")\n",
    "    print( best_model.cv_results_['params'][ np.argmin(best_model.cv_results_['rank_test_accuracy']) ] )\n",
    "    print(\"---WITH ACCURACY: ---\")\n",
    "    current_accuracy = best_model.cv_results_['mean_test_accuracy'][ np.argmax(best_model.cv_results_['mean_test_accuracy']) ]\n",
    "    print(current_accuracy)\n",
    "    accuracy_sum = accuracy_sum + current_accuracy\n",
    "    accuracy_scores.append(current_accuracy)\n",
    "    all_accuracy_models.append( best_model.cv_results_['params'][ np.argmin(best_model.cv_results_['rank_test_accuracy']) ] )\n",
    "    \n",
    "    print(\"---------------BEST MODEL FOR ROC: ---------------\")\n",
    "    print( best_model.cv_results_['params'][ np.argmin(best_model.cv_results_['rank_test_roc_auc_ovr']) ] )\n",
    "    print(\"---WITH ROC: ---\")\n",
    "    current_roc = best_model.cv_results_['mean_test_roc_auc_ovr'][ np.argmax(best_model.cv_results_['mean_test_roc_auc_ovr']) ]\n",
    "    print(current_roc)\n",
    "    roc_sum = roc_sum + current_roc\n",
    "    roc_scores.append(current_roc)\n",
    "    all_roc_models.append( best_model.cv_results_['params'][ np.argmin(best_model.cv_results_['rank_test_roc_auc_ovr']) ] )\n",
    "\n",
    "    \n",
    "    print(\"---------------BEST MODEL FOR F1: ----------------\")\n",
    "    print( best_model.cv_results_['params'][ np.argmin(best_model.cv_results_['rank_test_f1_micro']) ] )\n",
    "    print(\"---WITH F1: ---\")    \n",
    "    current_f1 = best_model.cv_results_['mean_test_f1_micro'][ np.argmax(best_model.cv_results_['mean_test_f1_micro']) ]\n",
    "    print(current_f1)\n",
    "    f1_sum = f1_sum + current_f1\n",
    "    f1_scores.append(current_f1)\n",
    "    all_f1_models.append( best_model.cv_results_['params'][ np.argmin(best_model.cv_results_['rank_test_f1_micro']) ] )\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get Train metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "===== ACCURACY SCORES: =====\n",
      "[0.8522000000000001, 0.8503999999999999, 0.842, 0.8486, 0.85]\n",
      "===== ROC SCORES: =====\n",
      "[0.9278945365199214, 0.9295282440075336, 0.9224028208840467, 0.929108595836999, 0.9280155579543168]\n",
      "===== F1 SCORES: =====\n",
      "[0.8522000000000001, 0.8503999999999999, 0.842, 0.8486, 0.85]\n"
     ]
    }
   ],
   "source": [
    "print(\"===== ACCURACY SCORES: =====\")\n",
    "print(accuracy_scores)\n",
    "print(\"===== ROC SCORES: =====\")\n",
    "print(roc_scores)\n",
    "print(\"===== F1 SCORES: =====\")\n",
    "print(f1_scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================ BEST ACCURACY MODEL IN TRAINING: ==================\n",
      "{'metric': 'manhattan', 'n_neighbors': 11, 'weights': 'distance'}\n",
      "WITH ACCURACY:\n",
      "0.8522000000000001\n",
      "================ BEST ROC MODEL IN TRAINING: ==================\n",
      "{'metric': 'manhattan', 'n_neighbors': 19, 'weights': 'distance'}\n",
      "WITH ROC SCORE:\n",
      "0.9295282440075336\n",
      "================ BEST F1 MODEL IN TRAINING: ==================\n",
      "{'metric': 'manhattan', 'n_neighbors': 11, 'weights': 'distance'}\n",
      "WITH F1 SCORE:\n",
      "0.8522000000000001\n"
     ]
    }
   ],
   "source": [
    "print(\"================ BEST ACCURACY MODEL IN TRAINING: ==================\")\n",
    "print(all_accuracy_models[ np.argmax(accuracy_scores) ])\n",
    "print(\"WITH ACCURACY:\")\n",
    "print(max(accuracy_scores))\n",
    "print(\"================ BEST ROC MODEL IN TRAINING: ==================\")\n",
    "print(all_roc_models[ np.argmax(roc_scores) ])\n",
    "print(\"WITH ROC SCORE:\")\n",
    "print(max(roc_scores))\n",
    "print(\"================ BEST F1 MODEL IN TRAINING: ==================\")\n",
    "print(all_f1_models[ np.argmax(f1_scores) ])\n",
    "print(\"WITH F1 SCORE:\")\n",
    "print(max(f1_scores))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================ AVERAGE ACCURACY ON TRAIN SET: ==================\n",
      "0.84864\n",
      "================ AVERAGE ROC SCORE ON TRAIN SET: ==================\n",
      "0.9273899510405634\n",
      "================ AVERAGE F1 SCORE ON TRAIN SET: ==================\n",
      "0.84864\n"
     ]
    }
   ],
   "source": [
    "print(\"================ AVERAGE ACCURACY ON TRAIN SET: ==================\")\n",
    "print(accuracy_sum / 5)\n",
    "print(\"================ AVERAGE ROC SCORE ON TRAIN SET: ==================\")\n",
    "print(roc_sum / 5)\n",
    "print(\"================ AVERAGE F1 SCORE ON TRAIN SET: ==================\")\n",
    "print(f1_sum / 5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get Test metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Trial 1</th>\n",
       "      <th>Trial 2</th>\n",
       "      <th>Trial 3</th>\n",
       "      <th>Trial 4</th>\n",
       "      <th>Trial 5</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>acc</th>\n",
       "      <td>0.849627</td>\n",
       "      <td>0.845723</td>\n",
       "      <td>0.853314</td>\n",
       "      <td>0.843642</td>\n",
       "      <td>0.848976</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>roc</th>\n",
       "      <td>0.849528</td>\n",
       "      <td>0.845662</td>\n",
       "      <td>0.853232</td>\n",
       "      <td>0.843673</td>\n",
       "      <td>0.848851</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>f1</th>\n",
       "      <td>0.846762</td>\n",
       "      <td>0.841651</td>\n",
       "      <td>0.849942</td>\n",
       "      <td>0.838406</td>\n",
       "      <td>0.845601</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      Trial 1   Trial 2   Trial 3   Trial 4   Trial 5\n",
       "acc  0.849627  0.845723  0.853314  0.843642  0.848976\n",
       "roc  0.849528  0.845662  0.853232  0.843673  0.848851\n",
       "f1   0.846762  0.841651  0.849942  0.838406  0.845601"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.metrics import f1_score\n",
    "\n",
    "# test performance of model rated as best for accuracy and f1 score on training set\n",
    "performance_AccModel = pd.DataFrame(index=['acc', 'roc', 'f1'], columns=['Trial 1', 'Trial 2', 'Trial 3', 'Trial 4', 'Trial 5'])\n",
    "performance_AccModel\n",
    "\n",
    "# test performance on trial 1 test set\n",
    "clf = KNeighborsClassifier(metric='manhattan', n_neighbors=11, weights='distance').fit(XY_train1.drop(['Y'],1), XY_train1['Y'])\n",
    "pred = clf.predict(XY_test1.drop(['Y'],1))\n",
    "performance_AccModel.loc['acc', 'Trial 1'] = accuracy_score(XY_test1['Y'], pred)\n",
    "performance_AccModel.loc['roc', 'Trial 1'] = roc_auc_score(XY_test1['Y'], pred)\n",
    "performance_AccModel.loc['f1', 'Trial 1'] = f1_score(XY_test1['Y'], pred)\n",
    "\n",
    "# test performance on trial 2 test set\n",
    "clf = KNeighborsClassifier(metric='manhattan', n_neighbors=11, weights='distance').fit(XY_train2.drop(['Y'],1), XY_train2['Y'])\n",
    "pred = clf.predict(XY_test2.drop(['Y'],1))\n",
    "performance_AccModel.loc['acc', 'Trial 2'] = accuracy_score(XY_test2['Y'], pred)\n",
    "performance_AccModel.loc['roc', 'Trial 2'] = roc_auc_score(XY_test2['Y'], pred)\n",
    "performance_AccModel.loc['f1', 'Trial 2'] = f1_score(XY_test2['Y'], pred)\n",
    "\n",
    "# test performance on trial 3 test set\n",
    "clf = KNeighborsClassifier(metric='manhattan', n_neighbors=11, weights='distance').fit(XY_train3.drop(['Y'],1), XY_train3['Y'])\n",
    "pred = clf.predict(XY_test3.drop(['Y'],1))\n",
    "performance_AccModel.loc['acc', 'Trial 3'] = accuracy_score(XY_test3['Y'], pred)\n",
    "performance_AccModel.loc['roc', 'Trial 3'] = roc_auc_score(XY_test3['Y'], pred)\n",
    "performance_AccModel.loc['f1', 'Trial 3'] = f1_score(XY_test3['Y'], pred)\n",
    "\n",
    "# test performance on trial 4 test set\n",
    "clf = KNeighborsClassifier(metric='manhattan', n_neighbors=11, weights='distance').fit(XY_train4.drop(['Y'],1), XY_train4['Y'])\n",
    "pred = clf.predict(XY_test4.drop(['Y'],1))\n",
    "performance_AccModel.loc['acc', 'Trial 4'] = accuracy_score(XY_test4['Y'], pred)\n",
    "performance_AccModel.loc['roc', 'Trial 4'] = roc_auc_score(XY_test4['Y'], pred)\n",
    "performance_AccModel.loc['f1', 'Trial 4'] = f1_score(XY_test4['Y'], pred)\n",
    "\n",
    "# test performance on trial 5 test set\n",
    "clf = KNeighborsClassifier(metric='manhattan', n_neighbors=11, weights='distance').fit(XY_train5.drop(['Y'],1), XY_train5['Y'])\n",
    "pred = clf.predict(XY_test5.drop(['Y'],1))\n",
    "performance_AccModel.loc['acc', 'Trial 5'] = accuracy_score(XY_test5['Y'], pred)\n",
    "performance_AccModel.loc['roc', 'Trial 5'] = roc_auc_score(XY_test5['Y'], pred)\n",
    "performance_AccModel.loc['f1', 'Trial 5'] = f1_score(XY_test5['Y'], pred)\n",
    "\n",
    "performance_AccModel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Trial 1</th>\n",
       "      <th>Trial 2</th>\n",
       "      <th>Trial 3</th>\n",
       "      <th>Trial 4</th>\n",
       "      <th>Trial 5</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>acc</th>\n",
       "      <td>0.84876</td>\n",
       "      <td>0.844422</td>\n",
       "      <td>0.853574</td>\n",
       "      <td>0.846634</td>\n",
       "      <td>0.849714</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>roc</th>\n",
       "      <td>0.848645</td>\n",
       "      <td>0.84435</td>\n",
       "      <td>0.853491</td>\n",
       "      <td>0.846668</td>\n",
       "      <td>0.849566</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>f1</th>\n",
       "      <td>0.845605</td>\n",
       "      <td>0.83963</td>\n",
       "      <td>0.850142</td>\n",
       "      <td>0.84115</td>\n",
       "      <td>0.845938</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      Trial 1   Trial 2   Trial 3   Trial 4   Trial 5\n",
       "acc   0.84876  0.844422  0.853574  0.846634  0.849714\n",
       "roc  0.848645   0.84435  0.853491  0.846668  0.849566\n",
       "f1   0.845605   0.83963  0.850142   0.84115  0.845938"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# test performance of model rated as best for roc on training set\n",
    "performance_ROCModel = pd.DataFrame(index=['acc', 'roc', 'f1'], columns=['Trial 1', 'Trial 2', 'Trial 3', 'Trial 4', 'Trial 5'])\n",
    "\n",
    "# test performance on trial 1 test set\n",
    "clf = KNeighborsClassifier(metric='manhattan', n_neighbors=19, weights='distance').fit(XY_train1.drop(['Y'],1), XY_train1['Y'])\n",
    "pred = clf.predict(XY_test1.drop(['Y'],1))\n",
    "performance_ROCModel.loc['acc', 'Trial 1'] = accuracy_score(XY_test1['Y'], pred)\n",
    "performance_ROCModel.loc['roc', 'Trial 1'] = roc_auc_score(XY_test1['Y'], pred)\n",
    "performance_ROCModel.loc['f1', 'Trial 1'] = f1_score(XY_test1['Y'], pred)\n",
    "\n",
    "# test performance on trial 2 test set\n",
    "clf = KNeighborsClassifier(metric='manhattan', n_neighbors=19, weights='distance').fit(XY_train2.drop(['Y'],1), XY_train2['Y'])\n",
    "pred = clf.predict(XY_test2.drop(['Y'],1))\n",
    "performance_ROCModel.loc['acc', 'Trial 2'] = accuracy_score(XY_test2['Y'], pred)\n",
    "performance_ROCModel.loc['roc', 'Trial 2'] = roc_auc_score(XY_test2['Y'], pred)\n",
    "performance_ROCModel.loc['f1', 'Trial 2'] = f1_score(XY_test2['Y'], pred)\n",
    "\n",
    "# test performance on trial 3 test set\n",
    "clf = KNeighborsClassifier(metric='manhattan', n_neighbors=19, weights='distance').fit(XY_train3.drop(['Y'],1), XY_train3['Y'])\n",
    "pred = clf.predict(XY_test3.drop(['Y'],1))\n",
    "performance_ROCModel.loc['acc', 'Trial 3'] = accuracy_score(XY_test3['Y'], pred)\n",
    "performance_ROCModel.loc['roc', 'Trial 3'] = roc_auc_score(XY_test3['Y'], pred)\n",
    "performance_ROCModel.loc['f1', 'Trial 3'] = f1_score(XY_test3['Y'], pred)\n",
    "\n",
    "# test performance on trial 4 test set\n",
    "clf = KNeighborsClassifier(metric='manhattan', n_neighbors=19, weights='distance').fit(XY_train4.drop(['Y'],1), XY_train4['Y'])\n",
    "pred = clf.predict(XY_test4.drop(['Y'],1))\n",
    "performance_ROCModel.loc['acc', 'Trial 4'] = accuracy_score(XY_test4['Y'], pred)\n",
    "performance_ROCModel.loc['roc', 'Trial 4'] = roc_auc_score(XY_test4['Y'], pred)\n",
    "performance_ROCModel.loc['f1', 'Trial 4'] = f1_score(XY_test4['Y'], pred)\n",
    "\n",
    "# test performance on trial 5 test set\n",
    "clf = KNeighborsClassifier(metric='manhattan', n_neighbors=19, weights='distance').fit(XY_train5.drop(['Y'],1), XY_train5['Y'])\n",
    "pred = clf.predict(XY_test5.drop(['Y'],1))\n",
    "performance_ROCModel.loc['acc', 'Trial 5'] = accuracy_score(XY_test5['Y'], pred)\n",
    "performance_ROCModel.loc['roc', 'Trial 5'] = roc_auc_score(XY_test5['Y'], pred)\n",
    "performance_ROCModel.loc['f1', 'Trial 5'] = f1_score(XY_test5['Y'], pred)\n",
    "\n",
    "performance_ROCModel"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get final KNN results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================ BEST ACCURACY MODEL IN KNN: ==================\n",
      "{'metric': 'manhattan', 'n_neighbors': 11, 'weights': 'distance'}\n",
      "WITH ACCURACY:\n",
      "0.8482564191533658\n",
      "================ BEST ROC MODEL IN KNN: ==================\n",
      "{'metric': 'manhattan', 'n_neighbors': 19, 'weights': 'distance'}\n",
      "WITH ROC SCORE:\n",
      "0.8485439141942365\n",
      "================ BEST F1 MODEL IN KNN: ==================\n",
      "{'metric': 'manhattan', 'n_neighbors': 11, 'weights': 'distance'}\n",
      "WITH F1 SCORE:\n",
      "0.8444725533216999\n"
     ]
    }
   ],
   "source": [
    "print(\"================ BEST ACCURACY MODEL IN KNN: ==================\")\n",
    "print(all_accuracy_models[ np.argmax(np.array(performance_AccModel.iloc[0])) ])\n",
    "print(\"WITH ACCURACY:\")\n",
    "print((np.array(performance_AccModel.iloc[0])).mean())\n",
    "print(\"================ BEST ROC MODEL IN KNN: ==================\")\n",
    "print(all_roc_models[ np.argmax(np.array(performance_ROCModel.iloc[1])) ])\n",
    "print(\"WITH ROC SCORE:\")\n",
    "print((performance_ROCModel.iloc[1]).mean())\n",
    "print(\"================ BEST F1 MODEL IN KNN: ==================\")\n",
    "print(all_f1_models[ np.argmax(np.array(performance_AccModel.iloc[2])) ])\n",
    "print(\"WITH F1 SCORE:\")\n",
    "print((np.array(performance_AccModel.iloc[2])).mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
