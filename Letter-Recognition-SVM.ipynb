{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%config InlineBackend.figure_format = 'retina'\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>letter</th>\n",
       "      <th>x-box</th>\n",
       "      <th>y-box</th>\n",
       "      <th>width</th>\n",
       "      <th>height</th>\n",
       "      <th>totpix</th>\n",
       "      <th>x-bar</th>\n",
       "      <th>y-bar</th>\n",
       "      <th>x2bar</th>\n",
       "      <th>y2bar</th>\n",
       "      <th>xybar</th>\n",
       "      <th>x2ybar</th>\n",
       "      <th>xy2bar</th>\n",
       "      <th>x-edge</th>\n",
       "      <th>x-edge-y</th>\n",
       "      <th>y-edge</th>\n",
       "      <th>y-edge-x</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>A</td>\n",
       "      <td>4</td>\n",
       "      <td>9</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>2</td>\n",
       "      <td>9</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>8</td>\n",
       "      <td>1</td>\n",
       "      <td>8</td>\n",
       "      <td>2</td>\n",
       "      <td>7</td>\n",
       "      <td>2</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>A</td>\n",
       "      <td>3</td>\n",
       "      <td>6</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>8</td>\n",
       "      <td>2</td>\n",
       "      <td>7</td>\n",
       "      <td>2</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>A</td>\n",
       "      <td>5</td>\n",
       "      <td>9</td>\n",
       "      <td>6</td>\n",
       "      <td>7</td>\n",
       "      <td>7</td>\n",
       "      <td>8</td>\n",
       "      <td>8</td>\n",
       "      <td>8</td>\n",
       "      <td>4</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>8</td>\n",
       "      <td>3</td>\n",
       "      <td>8</td>\n",
       "      <td>8</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>A</td>\n",
       "      <td>4</td>\n",
       "      <td>10</td>\n",
       "      <td>7</td>\n",
       "      <td>7</td>\n",
       "      <td>5</td>\n",
       "      <td>7</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>6</td>\n",
       "      <td>3</td>\n",
       "      <td>7</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>A</td>\n",
       "      <td>4</td>\n",
       "      <td>9</td>\n",
       "      <td>7</td>\n",
       "      <td>7</td>\n",
       "      <td>5</td>\n",
       "      <td>8</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  letter  x-box  y-box  width  height  totpix  x-bar  y-bar  x2bar  y2bar  \\\n",
       "0      A      4      9      6       6       2      9      5      3      1   \n",
       "1      A      3      6      5       4       1      7      5      3      1   \n",
       "2      A      5      9      6       7       7      8      8      8      4   \n",
       "3      A      4     10      7       7       5      7      5      2      3   \n",
       "4      A      4      9      7       7       5      8      5      2      4   \n",
       "\n",
       "   xybar  x2ybar  xy2bar  x-edge  x-edge-y  y-edge  y-edge-x  \n",
       "0      8       1       8       2         7       2         8  \n",
       "1      6       1       8       2         7       2         7  \n",
       "2      6       6       8       3         8       8         4  \n",
       "3      5       2       6       3         7       4         4  \n",
       "4      6       1       5       3         5       4         5  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "header = ['letter', 'x-box', 'y-box', 'width', 'height', 'totpix', \n",
    "         'x-bar', 'y-bar', 'x2bar', 'y2bar', 'xybar', 'x2ybar', 'xy2bar',\n",
    "         'x-edge', 'x-edge-y', 'y-edge', 'y-edge-x']\n",
    "letters = pd.read_csv('https://archive.ics.uci.edu/ml/machine-learning-databases/letter-recognition/letter-recognition.data', names=header)\n",
    "# letters = letters.set_index('letter') \n",
    "letters = letters.sort_values('letter') # order rows alphabetically\n",
    "letters = letters.reset_index(drop=True)\n",
    "letters.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(20000,)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>x-box</th>\n",
       "      <th>y-box</th>\n",
       "      <th>width</th>\n",
       "      <th>height</th>\n",
       "      <th>totpix</th>\n",
       "      <th>x-bar</th>\n",
       "      <th>y-bar</th>\n",
       "      <th>x2bar</th>\n",
       "      <th>y2bar</th>\n",
       "      <th>xybar</th>\n",
       "      <th>x2ybar</th>\n",
       "      <th>xy2bar</th>\n",
       "      <th>x-edge</th>\n",
       "      <th>x-edge-y</th>\n",
       "      <th>y-edge</th>\n",
       "      <th>y-edge-x</th>\n",
       "      <th>Y</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>4</td>\n",
       "      <td>9</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>2</td>\n",
       "      <td>9</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>8</td>\n",
       "      <td>1</td>\n",
       "      <td>8</td>\n",
       "      <td>2</td>\n",
       "      <td>7</td>\n",
       "      <td>2</td>\n",
       "      <td>8</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3</td>\n",
       "      <td>6</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>8</td>\n",
       "      <td>2</td>\n",
       "      <td>7</td>\n",
       "      <td>2</td>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5</td>\n",
       "      <td>9</td>\n",
       "      <td>6</td>\n",
       "      <td>7</td>\n",
       "      <td>7</td>\n",
       "      <td>8</td>\n",
       "      <td>8</td>\n",
       "      <td>8</td>\n",
       "      <td>4</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>8</td>\n",
       "      <td>3</td>\n",
       "      <td>8</td>\n",
       "      <td>8</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>10</td>\n",
       "      <td>7</td>\n",
       "      <td>7</td>\n",
       "      <td>5</td>\n",
       "      <td>7</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>6</td>\n",
       "      <td>3</td>\n",
       "      <td>7</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>9</td>\n",
       "      <td>7</td>\n",
       "      <td>7</td>\n",
       "      <td>5</td>\n",
       "      <td>8</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   x-box  y-box  width  height  totpix  x-bar  y-bar  x2bar  y2bar  xybar  \\\n",
       "0      4      9      6       6       2      9      5      3      1      8   \n",
       "1      3      6      5       4       1      7      5      3      1      6   \n",
       "2      5      9      6       7       7      8      8      8      4      6   \n",
       "3      4     10      7       7       5      7      5      2      3      5   \n",
       "4      4      9      7       7       5      8      5      2      4      6   \n",
       "\n",
       "   x2ybar  xy2bar  x-edge  x-edge-y  y-edge  y-edge-x  Y  \n",
       "0       1       8       2         7       2         8  1  \n",
       "1       1       8       2         7       2         7  1  \n",
       "2       6       8       3         8       8         4  1  \n",
       "3       2       6       3         7       4         4  1  \n",
       "4       1       5       3         5       4         5  1  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# make Y \n",
    "ones_pos = [1]*9940 # 9940 is the number of datapoints with letters A-M\n",
    "ones_neg = [-1]*(20000-9940) # the number of the rest of the datapoints with letters N-Z\n",
    "Y = np.array(ones_pos + ones_neg)\n",
    "print(Y.shape)\n",
    "# make X_and_Y\n",
    "letters_withY = letters\n",
    "letters_withY['Y'] = Y\n",
    "# letters_withY\n",
    "X_and_Y = letters_withY.drop('letter',1)\n",
    "X_and_Y.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create 5 trials, each with train and test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "XY_train1, XY_test1 = train_test_split(X_and_Y, test_size=15000, shuffle=True)\n",
    "XY_train2, XY_test2 = train_test_split(X_and_Y, test_size=15000, shuffle=True)\n",
    "XY_train3, XY_test3 = train_test_split(X_and_Y, test_size=15000, shuffle=True)\n",
    "XY_train4, XY_test4 = train_test_split(X_and_Y, test_size=15000, shuffle=True)\n",
    "XY_train5, XY_test5 = train_test_split(X_and_Y, test_size=15000, shuffle=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Perform GridSearchCV on classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------------------------------------------------------\n",
      "RESULTS FOR TRIAL:\n",
      "1\n",
      "------------------------------------------------------------------------------------\n",
      "---------------BEST MODEL FOR ACCURACY: ----------\n",
      "{'classifier': SVC(), 'classifier__C': 10.0, 'classifier__gamma': 1, 'classifier__kernel': 'rbf'}\n",
      "---WITH ACCURACY: ---\n",
      "0.9490000000000001\n",
      "---------------BEST MODEL FOR ROC: ---------------\n",
      "{'classifier': SVC(), 'classifier__C': 10.0, 'classifier__gamma': 1, 'classifier__kernel': 'rbf'}\n",
      "---WITH ROC: ---\n",
      "0.9892935852095409\n",
      "---------------BEST MODEL FOR F1: ----------------\n",
      "{'classifier': SVC(), 'classifier__C': 10.0, 'classifier__gamma': 1, 'classifier__kernel': 'rbf'}\n",
      "---WITH F1: ---\n",
      "0.9490000000000001\n",
      "------------------------------------------------------------------------------------\n",
      "RESULTS FOR TRIAL:\n",
      "2\n",
      "------------------------------------------------------------------------------------\n",
      "---------------BEST MODEL FOR ACCURACY: ----------\n",
      "{'classifier': SVC(), 'classifier__C': 10.0, 'classifier__gamma': 1, 'classifier__kernel': 'rbf'}\n",
      "---WITH ACCURACY: ---\n",
      "0.9570000000000001\n",
      "---------------BEST MODEL FOR ROC: ---------------\n",
      "{'classifier': SVC(), 'classifier__C': 10.0, 'classifier__gamma': 1, 'classifier__kernel': 'rbf'}\n",
      "---WITH ROC: ---\n",
      "0.9907812340114491\n",
      "---------------BEST MODEL FOR F1: ----------------\n",
      "{'classifier': SVC(), 'classifier__C': 10.0, 'classifier__gamma': 1, 'classifier__kernel': 'rbf'}\n",
      "---WITH F1: ---\n",
      "0.9570000000000001\n",
      "------------------------------------------------------------------------------------\n",
      "RESULTS FOR TRIAL:\n",
      "3\n",
      "------------------------------------------------------------------------------------\n",
      "---------------BEST MODEL FOR ACCURACY: ----------\n",
      "{'classifier': SVC(), 'classifier__C': 10.0, 'classifier__gamma': 1, 'classifier__kernel': 'rbf'}\n",
      "---WITH ACCURACY: ---\n",
      "0.9501999999999999\n",
      "---------------BEST MODEL FOR ROC: ---------------\n",
      "{'classifier': SVC(), 'classifier__C': 10.0, 'classifier__gamma': 1, 'classifier__kernel': 'rbf'}\n",
      "---WITH ROC: ---\n",
      "0.9897851060968004\n",
      "---------------BEST MODEL FOR F1: ----------------\n",
      "{'classifier': SVC(), 'classifier__C': 10.0, 'classifier__gamma': 1, 'classifier__kernel': 'rbf'}\n",
      "---WITH F1: ---\n",
      "0.9501999999999999\n",
      "------------------------------------------------------------------------------------\n",
      "RESULTS FOR TRIAL:\n",
      "4\n",
      "------------------------------------------------------------------------------------\n",
      "---------------BEST MODEL FOR ACCURACY: ----------\n",
      "{'classifier': SVC(), 'classifier__C': 10.0, 'classifier__gamma': 1, 'classifier__kernel': 'rbf'}\n",
      "---WITH ACCURACY: ---\n",
      "0.9565999999999999\n",
      "---------------BEST MODEL FOR ROC: ---------------\n",
      "{'classifier': SVC(), 'classifier__C': 10.0, 'classifier__gamma': 1, 'classifier__kernel': 'rbf'}\n",
      "---WITH ROC: ---\n",
      "0.9907151628606513\n",
      "---------------BEST MODEL FOR F1: ----------------\n",
      "{'classifier': SVC(), 'classifier__C': 10.0, 'classifier__gamma': 1, 'classifier__kernel': 'rbf'}\n",
      "---WITH F1: ---\n",
      "0.9565999999999999\n",
      "------------------------------------------------------------------------------------\n",
      "RESULTS FOR TRIAL:\n",
      "5\n",
      "------------------------------------------------------------------------------------\n",
      "---------------BEST MODEL FOR ACCURACY: ----------\n",
      "{'classifier': SVC(), 'classifier__C': 1.0, 'classifier__gamma': 1, 'classifier__kernel': 'rbf'}\n",
      "---WITH ACCURACY: ---\n",
      "0.9538\n",
      "---------------BEST MODEL FOR ROC: ---------------\n",
      "{'classifier': SVC(), 'classifier__C': 10.0, 'classifier__gamma': 1, 'classifier__kernel': 'rbf'}\n",
      "---WITH ROC: ---\n",
      "0.9904123357804681\n",
      "---------------BEST MODEL FOR F1: ----------------\n",
      "{'classifier': SVC(), 'classifier__C': 1.0, 'classifier__gamma': 1, 'classifier__kernel': 'rbf'}\n",
      "---WITH F1: ---\n",
      "0.9538\n",
      "Wall time: 47min 10s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "#import warnings\n",
    "# there are a lot of convergence warnings for some params, however be careful with this!!\n",
    "# sometimes you need to see those wanrings, and now we've screwed tha tup for the whole notebook from here on!!\n",
    "#warnings.filterwarnings('ignore')\n",
    "\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn import datasets\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.svm import SVC\n",
    "import numpy as np\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn import preprocessing\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "\n",
    "\n",
    "# Create a pipeline - RF is a stand in, we will populate the classifier part below\n",
    "pipe = Pipeline([('std', StandardScaler()),\n",
    "                 ('classifier', SVC())])\n",
    "\n",
    "# Create search space of candidate learning algorithms and their hyperparameters\n",
    "# search_space = [{'classifier': [SVC()],\n",
    "#                  'classifier__kernel': ['rbf'],\n",
    "#                  'classifier__gamma': [0.001, 0.01, 0.1, 1, 10],\n",
    "#                  'classifier__C': np.logspace(-4, 4, 9)},\n",
    "#                 {'classifier': [SVC()],\n",
    "#                  'classifier__kernel': ['linear'],\n",
    "#                  'classifier__C': np.logspace(-4, 4, 9)},\n",
    "#                 {'classifier': [SVC()],\n",
    "#                  'classifier__kernel': ['poly'],\n",
    "#                  'classifier__degree': [2,3],\n",
    "#                  'classifier__C': np.logspace(-4, 4, 9)}\n",
    "#                 ]\n",
    "search_space = [{'classifier': [SVC()],\n",
    "                 'classifier__kernel': ['rbf'],\n",
    "                 'classifier__gamma': [0.001, 0.1, 1, 1],\n",
    "                 'classifier__C': np.logspace(-2, 2, 5)},\n",
    "                {'classifier': [SVC()],\n",
    "                 'classifier__kernel': ['linear'],\n",
    "                 'classifier__C': np.logspace(-2, 2, 5)},\n",
    "                {'classifier': [SVC()],\n",
    "                 'classifier__kernel': ['poly'],\n",
    "                 'classifier__degree': [2,3],\n",
    "                 'classifier__C': np.logspace(-2, 2, 5)}\n",
    "                ]\n",
    "\n",
    "trialnum = 0\n",
    "accuracy_sum = 0 # sum of top accuracy to later calculate the average of all 5 trials\n",
    "roc_sum = 0 # sum of top roc score to later calculate the average of all 5 trials\n",
    "f1_sum = 0 # sum of top accuracy to later calculate the average of all 5 trials\n",
    "accuracy_scores = []\n",
    "roc_scores = []\n",
    "f1_scores = []\n",
    "all_accuracy_models = []\n",
    "all_roc_models = []\n",
    "all_f1_models = []\n",
    "\n",
    "# for every trial\n",
    "for trial in [XY_train1, XY_train2, XY_train3, XY_train4, XY_train5]:\n",
    " \n",
    "    trialnum = trialnum + 1\n",
    "\n",
    "    X_l = trial.drop(['Y'],1)\n",
    "    y_l = trial['Y']\n",
    "\n",
    "    # Create grid search \n",
    "    clf = GridSearchCV(pipe, search_space, cv=StratifiedKFold(n_splits=5), \n",
    "                       scoring=['accuracy', 'roc_auc', 'f1_micro'], refit=False,\n",
    "                       verbose=0)\n",
    "\n",
    "    # Fit grid search\n",
    "    best_model = clf.fit(X_l, y_l)\n",
    "    \n",
    "    print(\"------------------------------------------------------------------------------------\")\n",
    "    print(\"RESULTS FOR TRIAL:\")\n",
    "    print(trialnum)\n",
    "    print(\"------------------------------------------------------------------------------------\")\n",
    "    \n",
    "    # the detailed results of the whole model selection search...\n",
    "#     print(best_model.cv_results_)\n",
    "\n",
    "    print(\"---------------BEST MODEL FOR ACCURACY: ----------\")\n",
    "    print( best_model.cv_results_['params'][ np.argmin(best_model.cv_results_['rank_test_accuracy']) ] )\n",
    "    print(\"---WITH ACCURACY: ---\")\n",
    "    current_accuracy = best_model.cv_results_['mean_test_accuracy'][ np.argmax(best_model.cv_results_['mean_test_accuracy']) ]\n",
    "    print(current_accuracy)\n",
    "    accuracy_sum = accuracy_sum + current_accuracy\n",
    "    accuracy_scores.append(current_accuracy)\n",
    "    all_accuracy_models.append( best_model.cv_results_['params'][ np.argmin(best_model.cv_results_['rank_test_accuracy']) ] )\n",
    "    \n",
    "    print(\"---------------BEST MODEL FOR ROC: ---------------\")\n",
    "    print( best_model.cv_results_['params'][ np.argmin(best_model.cv_results_['rank_test_roc_auc']) ] )\n",
    "    print(\"---WITH ROC: ---\")\n",
    "    current_roc = best_model.cv_results_['mean_test_roc_auc'][ np.argmax(best_model.cv_results_['mean_test_roc_auc']) ]\n",
    "    print(current_roc)\n",
    "    roc_sum = roc_sum + current_roc\n",
    "    roc_scores.append(current_roc)\n",
    "    all_roc_models.append( best_model.cv_results_['params'][ np.argmin(best_model.cv_results_['rank_test_roc_auc']) ] )\n",
    "\n",
    "    \n",
    "    print(\"---------------BEST MODEL FOR F1: ----------------\")\n",
    "    print( best_model.cv_results_['params'][ np.argmin(best_model.cv_results_['rank_test_f1_micro']) ] )\n",
    "    print(\"---WITH F1: ---\")    \n",
    "    current_f1 = best_model.cv_results_['mean_test_f1_micro'][ np.argmax(best_model.cv_results_['mean_test_f1_micro']) ]\n",
    "    print(current_f1)\n",
    "    f1_sum = f1_sum + current_f1\n",
    "    f1_scores.append(current_f1)\n",
    "    all_f1_models.append( best_model.cv_results_['params'][ np.argmin(best_model.cv_results_['rank_test_f1_micro']) ] )\n",
    "\n",
    "    \n",
    "    # below (optional): check that the above outputs actually show best scores\n",
    "\n",
    "#     print results just to check alignment with the above\n",
    "#     results = pd.DataFrame( best_model.cv_results_['params'] ) # parameter settings for best model\n",
    "#     grab the accuracy score resulting from those parameters\n",
    "#     results['score_acc'] = best_model.cv_results_['mean_test_accuracy']\n",
    "#     results['score_roc'] = best_model.cv_results_['mean_test_roc_auc_ovr']\n",
    "#     results['score_f1'] = best_model.cv_results_['mean_test_f1_micro']\n",
    "#     get rid of classifier__XX in columns\n",
    "#     cols = results.columns.to_series().str.split('__').apply(lambda x: x[-1])\n",
    "#     results.columns = cols\n",
    "#     print(results)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get Training Metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "===== ACCURACY SCORES: =====\n",
      "[0.9490000000000001, 0.9570000000000001, 0.9501999999999999, 0.9565999999999999, 0.9538]\n",
      "===== ROC SCORES: =====\n",
      "[0.9892935852095409, 0.9907812340114491, 0.9897851060968004, 0.9907151628606513, 0.9904123357804681]\n",
      "===== F1 SCORES: =====\n",
      "[0.9490000000000001, 0.9570000000000001, 0.9501999999999999, 0.9565999999999999, 0.9538]\n"
     ]
    }
   ],
   "source": [
    "print(\"===== ACCURACY SCORES: =====\")\n",
    "print(accuracy_scores)\n",
    "print(\"===== ROC SCORES: =====\")\n",
    "print(roc_scores)\n",
    "print(\"===== F1 SCORES: =====\")\n",
    "print(f1_scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================ BEST ACCURACY MODEL IN TRAINING: ==================\n",
      "{'classifier': SVC(), 'classifier__C': 10.0, 'classifier__gamma': 1, 'classifier__kernel': 'rbf'}\n",
      "WITH ACCURACY:\n",
      "0.9570000000000001\n",
      "================ BEST ROC MODEL IN TRAINING: ==================\n",
      "{'classifier': SVC(), 'classifier__C': 10.0, 'classifier__gamma': 1, 'classifier__kernel': 'rbf'}\n",
      "WITH ROC SCORE:\n",
      "0.9907812340114491\n",
      "================ BEST F1 MODEL IN TRAINING: ==================\n",
      "{'classifier': SVC(), 'classifier__C': 10.0, 'classifier__gamma': 1, 'classifier__kernel': 'rbf'}\n",
      "WITH F1 SCORE:\n",
      "0.9570000000000001\n"
     ]
    }
   ],
   "source": [
    "print(\"================ BEST ACCURACY MODEL IN TRAINING: ==================\")\n",
    "print(all_accuracy_models[ np.argmax(accuracy_scores) ])\n",
    "print(\"WITH ACCURACY:\")\n",
    "print(max(accuracy_scores))\n",
    "print(\"================ BEST ROC MODEL IN TRAINING: ==================\")\n",
    "print(all_roc_models[ np.argmax(roc_scores) ])\n",
    "print(\"WITH ROC SCORE:\")\n",
    "print(max(roc_scores))\n",
    "print(\"================ BEST F1 MODEL IN TRAINING: ==================\")\n",
    "print(all_f1_models[ np.argmax(f1_scores) ])\n",
    "print(\"WITH F1 SCORE:\")\n",
    "print(max(f1_scores))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================ AVERAGE ACCURACY ON TRAIN SET: ==================\n",
      "0.9533200000000001\n",
      "================ AVERAGE ROC SCORE ON TRAIN SET: ==================\n",
      "0.990197484791782\n",
      "================ AVERAGE F1 SCORE ON TRAIN SET: ==================\n",
      "0.9533200000000001\n"
     ]
    }
   ],
   "source": [
    "print(\"================ AVERAGE ACCURACY ON TRAIN SET: ==================\")\n",
    "print(accuracy_sum / 5)\n",
    "print(\"================ AVERAGE ROC SCORE ON TRAIN SET: ==================\")\n",
    "print(roc_sum / 5)\n",
    "print(\"================ AVERAGE F1 SCORE ON TRAIN SET: ==================\")\n",
    "print(f1_sum / 5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get Test Metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Trial 1</th>\n",
       "      <th>Trial 2</th>\n",
       "      <th>Trial 3</th>\n",
       "      <th>Trial 4</th>\n",
       "      <th>Trial 5</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>acc</th>\n",
       "      <td>0.8346</td>\n",
       "      <td>0.757267</td>\n",
       "      <td>0.687867</td>\n",
       "      <td>0.799067</td>\n",
       "      <td>0.795867</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>roc</th>\n",
       "      <td>0.8333</td>\n",
       "      <td>0.760039</td>\n",
       "      <td>0.687117</td>\n",
       "      <td>0.797344</td>\n",
       "      <td>0.797884</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>f1</th>\n",
       "      <td>0.802106</td>\n",
       "      <td>0.802238</td>\n",
       "      <td>0.544995</td>\n",
       "      <td>0.74702</td>\n",
       "      <td>0.828209</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      Trial 1   Trial 2   Trial 3   Trial 4   Trial 5\n",
       "acc    0.8346  0.757267  0.687867  0.799067  0.795867\n",
       "roc    0.8333  0.760039  0.687117  0.797344  0.797884\n",
       "f1   0.802106  0.802238  0.544995   0.74702  0.828209"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.metrics import f1_score\n",
    "\n",
    "# test performance of model rated as best for accuracy and roc and f1 score on training set\n",
    "performance_AccModel = pd.DataFrame(index=['acc', 'roc', 'f1'], columns=['Trial 1', 'Trial 2', 'Trial 3', 'Trial 4', 'Trial 5'])\n",
    "performance_AccModel\n",
    "\n",
    "# test performance on trial 1 test set\n",
    "clf = SVC(C=10.0, gamma=1.0, kernel='rbf').fit(XY_train1.drop(['Y'],1), XY_train1['Y'])\n",
    "pred = clf.predict(XY_test1.drop(['Y'],1))\n",
    "performance_AccModel.loc['acc', 'Trial 1'] = accuracy_score(XY_test1['Y'], pred)\n",
    "performance_AccModel.loc['roc', 'Trial 1'] = roc_auc_score(XY_test1['Y'], pred)\n",
    "performance_AccModel.loc['f1', 'Trial 1'] = f1_score(XY_test1['Y'], pred)\n",
    "\n",
    "# test performance on trial 2 test set\n",
    "clf = SVC(C=10.0, gamma=1.0, kernel='rbf').fit(XY_train2.drop(['Y'],1), XY_train2['Y'])\n",
    "pred = clf.predict(XY_test2.drop(['Y'],1))\n",
    "performance_AccModel.loc['acc', 'Trial 2'] = accuracy_score(XY_test2['Y'], pred)\n",
    "performance_AccModel.loc['roc', 'Trial 2'] = roc_auc_score(XY_test2['Y'], pred)\n",
    "performance_AccModel.loc['f1', 'Trial 2'] = f1_score(XY_test2['Y'], pred)\n",
    "\n",
    "# test performance on trial 3 test set\n",
    "clf = SVC(C=10.0, gamma=1.0, kernel='rbf').fit(XY_train3.drop(['Y'],1), XY_train3['Y'])\n",
    "pred = clf.predict(XY_test3.drop(['Y'],1))\n",
    "performance_AccModel.loc['acc', 'Trial 3'] = accuracy_score(XY_test3['Y'], pred)\n",
    "performance_AccModel.loc['roc', 'Trial 3'] = roc_auc_score(XY_test3['Y'], pred)\n",
    "performance_AccModel.loc['f1', 'Trial 3'] = f1_score(XY_test3['Y'], pred)\n",
    "\n",
    "# test performance on trial 4 test set\n",
    "clf = SVC(C=10.0, gamma=1.0, kernel='rbf').fit(XY_train4.drop(['Y'],1), XY_train4['Y'])\n",
    "pred = clf.predict(XY_test4.drop(['Y'],1))\n",
    "performance_AccModel.loc['acc', 'Trial 4'] = accuracy_score(XY_test4['Y'], pred)\n",
    "performance_AccModel.loc['roc', 'Trial 4'] = roc_auc_score(XY_test4['Y'], pred)\n",
    "performance_AccModel.loc['f1', 'Trial 4'] = f1_score(XY_test4['Y'], pred)\n",
    "\n",
    "# test performance on trial 5 test set\n",
    "clf = SVC(C=10.0, gamma=1.0, kernel='rbf').fit(XY_train5.drop(['Y'],1), XY_train5['Y'])\n",
    "pred = clf.predict(XY_test5.drop(['Y'],1))\n",
    "performance_AccModel.loc['acc', 'Trial 5'] = accuracy_score(XY_test5['Y'], pred)\n",
    "performance_AccModel.loc['roc', 'Trial 5'] = roc_auc_score(XY_test5['Y'], pred)\n",
    "performance_AccModel.loc['f1', 'Trial 5'] = f1_score(XY_test5['Y'], pred)\n",
    "\n",
    "performance_AccModel"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get final SVC results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================ BEST ACCURACY MODEL IN SVC: ==================\n",
      "{'classifier': SVC(), 'classifier__C': 10.0, 'classifier__gamma': 1, 'classifier__kernel': 'rbf'}\n",
      "WITH ACCURACY:\n",
      "0.7749333333333334\n",
      "================ BEST ROC MODEL IN SVC: ==================\n",
      "{'classifier': SVC(), 'classifier__C': 10.0, 'classifier__gamma': 1, 'classifier__kernel': 'rbf'}\n",
      "WITH ROC SCORE:\n",
      "0.7751366435681344\n",
      "================ BEST F1 MODEL IN SVC: ==================\n",
      "{'classifier': SVC(), 'classifier__C': 1.0, 'classifier__gamma': 1, 'classifier__kernel': 'rbf'}\n",
      "WITH F1 SCORE:\n",
      "0.744913633779794\n"
     ]
    }
   ],
   "source": [
    "print(\"================ BEST ACCURACY MODEL IN SVC: ==================\")\n",
    "print(all_accuracy_models[ np.argmax(np.array(performance_AccModel.iloc[0])) ])\n",
    "print(\"WITH ACCURACY:\")\n",
    "print((np.array(performance_AccModel.iloc[0])).mean())\n",
    "print(\"================ BEST ROC MODEL IN SVC: ==================\")\n",
    "print(all_roc_models[ np.argmax(np.array(performance_AccModel.iloc[1])) ])\n",
    "print(\"WITH ROC SCORE:\")\n",
    "print((performance_AccModel.iloc[1]).mean())\n",
    "print(\"================ BEST F1 MODEL IN SVC: ==================\")\n",
    "print(all_f1_models[ np.argmax(np.array(performance_AccModel.iloc[2])) ])\n",
    "print(\"WITH F1 SCORE:\")\n",
    "print((np.array(performance_AccModel.iloc[2])).mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
