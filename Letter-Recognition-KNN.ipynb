{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Letter Recognition using KNN\n",
    "\n",
    "sources:\n",
    "https://medium.com/@erikgreenj/k-neighbors-classifier-with-gridsearchcv-basics-3c445ddeb657"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Format the Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "%config InlineBackend.figure_format = 'retina'\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>letter</th>\n",
       "      <th>x-box</th>\n",
       "      <th>y-box</th>\n",
       "      <th>width</th>\n",
       "      <th>height</th>\n",
       "      <th>totpix</th>\n",
       "      <th>x-bar</th>\n",
       "      <th>y-bar</th>\n",
       "      <th>x2bar</th>\n",
       "      <th>y2bar</th>\n",
       "      <th>xybar</th>\n",
       "      <th>x2ybar</th>\n",
       "      <th>xy2bar</th>\n",
       "      <th>x-edge</th>\n",
       "      <th>x-edge-y</th>\n",
       "      <th>y-edge</th>\n",
       "      <th>y-edge-x</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>A</td>\n",
       "      <td>4</td>\n",
       "      <td>9</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>2</td>\n",
       "      <td>9</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>8</td>\n",
       "      <td>1</td>\n",
       "      <td>8</td>\n",
       "      <td>2</td>\n",
       "      <td>7</td>\n",
       "      <td>2</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>A</td>\n",
       "      <td>3</td>\n",
       "      <td>6</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>8</td>\n",
       "      <td>2</td>\n",
       "      <td>7</td>\n",
       "      <td>2</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>A</td>\n",
       "      <td>5</td>\n",
       "      <td>9</td>\n",
       "      <td>6</td>\n",
       "      <td>7</td>\n",
       "      <td>7</td>\n",
       "      <td>8</td>\n",
       "      <td>8</td>\n",
       "      <td>8</td>\n",
       "      <td>4</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>8</td>\n",
       "      <td>3</td>\n",
       "      <td>8</td>\n",
       "      <td>8</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>A</td>\n",
       "      <td>4</td>\n",
       "      <td>10</td>\n",
       "      <td>7</td>\n",
       "      <td>7</td>\n",
       "      <td>5</td>\n",
       "      <td>7</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>6</td>\n",
       "      <td>3</td>\n",
       "      <td>7</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>A</td>\n",
       "      <td>4</td>\n",
       "      <td>9</td>\n",
       "      <td>7</td>\n",
       "      <td>7</td>\n",
       "      <td>5</td>\n",
       "      <td>8</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  letter  x-box  y-box  width  height  totpix  x-bar  y-bar  x2bar  y2bar  \\\n",
       "0      A      4      9      6       6       2      9      5      3      1   \n",
       "1      A      3      6      5       4       1      7      5      3      1   \n",
       "2      A      5      9      6       7       7      8      8      8      4   \n",
       "3      A      4     10      7       7       5      7      5      2      3   \n",
       "4      A      4      9      7       7       5      8      5      2      4   \n",
       "\n",
       "   xybar  x2ybar  xy2bar  x-edge  x-edge-y  y-edge  y-edge-x  \n",
       "0      8       1       8       2         7       2         8  \n",
       "1      6       1       8       2         7       2         7  \n",
       "2      6       6       8       3         8       8         4  \n",
       "3      5       2       6       3         7       4         4  \n",
       "4      6       1       5       3         5       4         5  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "header = ['letter', 'x-box', 'y-box', 'width', 'height', 'totpix', \n",
    "         'x-bar', 'y-bar', 'x2bar', 'y2bar', 'xybar', 'x2ybar', 'xy2bar',\n",
    "         'x-edge', 'x-edge-y', 'y-edge', 'y-edge-x']\n",
    "letters = pd.read_csv('https://archive.ics.uci.edu/ml/machine-learning-databases/letter-recognition/letter-recognition.data', names=header)\n",
    "# letters = letters.set_index('letter') \n",
    "letters = letters.sort_values('letter') # order rows alphabetically\n",
    "letters = letters.reset_index(drop=True)\n",
    "letters.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(20000,)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>x-box</th>\n",
       "      <th>y-box</th>\n",
       "      <th>width</th>\n",
       "      <th>height</th>\n",
       "      <th>totpix</th>\n",
       "      <th>x-bar</th>\n",
       "      <th>y-bar</th>\n",
       "      <th>x2bar</th>\n",
       "      <th>y2bar</th>\n",
       "      <th>xybar</th>\n",
       "      <th>x2ybar</th>\n",
       "      <th>xy2bar</th>\n",
       "      <th>x-edge</th>\n",
       "      <th>x-edge-y</th>\n",
       "      <th>y-edge</th>\n",
       "      <th>y-edge-x</th>\n",
       "      <th>Y</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>4</td>\n",
       "      <td>9</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>2</td>\n",
       "      <td>9</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>8</td>\n",
       "      <td>1</td>\n",
       "      <td>8</td>\n",
       "      <td>2</td>\n",
       "      <td>7</td>\n",
       "      <td>2</td>\n",
       "      <td>8</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3</td>\n",
       "      <td>6</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>8</td>\n",
       "      <td>2</td>\n",
       "      <td>7</td>\n",
       "      <td>2</td>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5</td>\n",
       "      <td>9</td>\n",
       "      <td>6</td>\n",
       "      <td>7</td>\n",
       "      <td>7</td>\n",
       "      <td>8</td>\n",
       "      <td>8</td>\n",
       "      <td>8</td>\n",
       "      <td>4</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>8</td>\n",
       "      <td>3</td>\n",
       "      <td>8</td>\n",
       "      <td>8</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>10</td>\n",
       "      <td>7</td>\n",
       "      <td>7</td>\n",
       "      <td>5</td>\n",
       "      <td>7</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>6</td>\n",
       "      <td>3</td>\n",
       "      <td>7</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>9</td>\n",
       "      <td>7</td>\n",
       "      <td>7</td>\n",
       "      <td>5</td>\n",
       "      <td>8</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   x-box  y-box  width  height  totpix  x-bar  y-bar  x2bar  y2bar  xybar  \\\n",
       "0      4      9      6       6       2      9      5      3      1      8   \n",
       "1      3      6      5       4       1      7      5      3      1      6   \n",
       "2      5      9      6       7       7      8      8      8      4      6   \n",
       "3      4     10      7       7       5      7      5      2      3      5   \n",
       "4      4      9      7       7       5      8      5      2      4      6   \n",
       "\n",
       "   x2ybar  xy2bar  x-edge  x-edge-y  y-edge  y-edge-x  Y  \n",
       "0       1       8       2         7       2         8  1  \n",
       "1       1       8       2         7       2         7  1  \n",
       "2       6       8       3         8       8         4  1  \n",
       "3       2       6       3         7       4         4  1  \n",
       "4       1       5       3         5       4         5  1  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# make Y \n",
    "ones_pos = [1]*9940 # 9940 is the number of datapoints with letters A-M\n",
    "ones_neg = [-1]*(20000-9940) # the number of the rest of the datapoints with letters N-Z\n",
    "Y = np.array(ones_pos + ones_neg)\n",
    "print(Y.shape)\n",
    "# make X_and_Y\n",
    "letters_withY = letters\n",
    "letters_withY['Y'] = Y\n",
    "# letters_withY\n",
    "X_and_Y = letters_withY.drop('letter',1)\n",
    "X_and_Y.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create 5 trials, each with train and test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "XY_train1, XY_test1 = train_test_split(X_and_Y, test_size=15000, shuffle=True)\n",
    "XY_train2, XY_test2 = train_test_split(X_and_Y, test_size=15000, shuffle=True)\n",
    "XY_train3, XY_test3 = train_test_split(X_and_Y, test_size=15000, shuffle=True)\n",
    "XY_train4, XY_test4 = train_test_split(X_and_Y, test_size=15000, shuffle=True)\n",
    "XY_train5, XY_test5 = train_test_split(X_and_Y, test_size=15000, shuffle=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Perform GridSearchCV on classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------------------------------------------------------\n",
      "RESULTS FOR TRIAL:\n",
      "1\n",
      "------------------------------------------------------------------------------------\n",
      "---------------BEST MODEL FOR ACCURACY: ----------\n",
      "{'metric': 'euclidean', 'n_neighbors': 3, 'weights': 'distance'}\n",
      "---WITH ACCURACY: ---\n",
      "0.9461999999999999\n",
      "---------------BEST MODEL FOR ROC: ---------------\n",
      "{'metric': 'manhattan', 'n_neighbors': 5, 'weights': 'distance'}\n",
      "---WITH ROC: ---\n",
      "0.9874878374135492\n",
      "---------------BEST MODEL FOR F1: ----------------\n",
      "{'metric': 'euclidean', 'n_neighbors': 3, 'weights': 'distance'}\n",
      "---WITH F1: ---\n",
      "0.9461999999999999\n",
      "------------------------------------------------------------------------------------\n",
      "RESULTS FOR TRIAL:\n",
      "2\n",
      "------------------------------------------------------------------------------------\n",
      "---------------BEST MODEL FOR ACCURACY: ----------\n",
      "{'metric': 'manhattan', 'n_neighbors': 3, 'weights': 'distance'}\n",
      "---WITH ACCURACY: ---\n",
      "0.9521999999999998\n",
      "---------------BEST MODEL FOR ROC: ---------------\n",
      "{'metric': 'euclidean', 'n_neighbors': 5, 'weights': 'distance'}\n",
      "---WITH ROC: ---\n",
      "0.9885579215200169\n",
      "---------------BEST MODEL FOR F1: ----------------\n",
      "{'metric': 'manhattan', 'n_neighbors': 3, 'weights': 'distance'}\n",
      "---WITH F1: ---\n",
      "0.9522\n",
      "------------------------------------------------------------------------------------\n",
      "RESULTS FOR TRIAL:\n",
      "3\n",
      "------------------------------------------------------------------------------------\n",
      "---------------BEST MODEL FOR ACCURACY: ----------\n",
      "{'metric': 'manhattan', 'n_neighbors': 3, 'weights': 'distance'}\n",
      "---WITH ACCURACY: ---\n",
      "0.9488\n",
      "---------------BEST MODEL FOR ROC: ---------------\n",
      "{'metric': 'manhattan', 'n_neighbors': 5, 'weights': 'distance'}\n",
      "---WITH ROC: ---\n",
      "0.9867112980264757\n",
      "---------------BEST MODEL FOR F1: ----------------\n",
      "{'metric': 'manhattan', 'n_neighbors': 3, 'weights': 'distance'}\n",
      "---WITH F1: ---\n",
      "0.9488\n",
      "------------------------------------------------------------------------------------\n",
      "RESULTS FOR TRIAL:\n",
      "4\n",
      "------------------------------------------------------------------------------------\n",
      "---------------BEST MODEL FOR ACCURACY: ----------\n",
      "{'metric': 'manhattan', 'n_neighbors': 5, 'weights': 'distance'}\n",
      "---WITH ACCURACY: ---\n",
      "0.9456\n",
      "---------------BEST MODEL FOR ROC: ---------------\n",
      "{'metric': 'euclidean', 'n_neighbors': 5, 'weights': 'distance'}\n",
      "---WITH ROC: ---\n",
      "0.9881638728062573\n",
      "---------------BEST MODEL FOR F1: ----------------\n",
      "{'metric': 'manhattan', 'n_neighbors': 5, 'weights': 'distance'}\n",
      "---WITH F1: ---\n",
      "0.9456\n",
      "------------------------------------------------------------------------------------\n",
      "RESULTS FOR TRIAL:\n",
      "5\n",
      "------------------------------------------------------------------------------------\n",
      "---------------BEST MODEL FOR ACCURACY: ----------\n",
      "{'metric': 'manhattan', 'n_neighbors': 3, 'weights': 'distance'}\n",
      "---WITH ACCURACY: ---\n",
      "0.9475999999999999\n",
      "---------------BEST MODEL FOR ROC: ---------------\n",
      "{'metric': 'manhattan', 'n_neighbors': 5, 'weights': 'distance'}\n",
      "---WITH ROC: ---\n",
      "0.9893954494840684\n",
      "---------------BEST MODEL FOR F1: ----------------\n",
      "{'metric': 'manhattan', 'n_neighbors': 3, 'weights': 'distance'}\n",
      "---WITH F1: ---\n",
      "0.9475999999999999\n",
      "Wall time: 34.5 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "#import warnings\n",
    "# there are a lot of convergence warnings for some params, however be careful with this!!\n",
    "# sometimes you need to see those wanrings, and now we've screwed tha tup for the whole notebook from here on!!\n",
    "#warnings.filterwarnings('ignore')\n",
    "\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn import datasets\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "import numpy as np\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "# Create a pipeline - RF is a stand in, we will populate the classifier part below\n",
    "pipe = Pipeline([('std', StandardScaler()),\n",
    "                 ('classifier', KNeighborsClassifier())])\n",
    "\n",
    "# Create search space of candidate learning algorithms and their hyperparameters\n",
    "grid_params = {\n",
    "    'n_neighbors': [3,5,11,19],\n",
    "    'weights': ['uniform', 'distance'],\n",
    "    'metric': ['euclidean', 'manhattan']\n",
    "}\n",
    "\n",
    "trialnum = 0\n",
    "accuracy_sum = 0 # sum of top accuracy to later calculate the average of all 5 trials\n",
    "roc_sum = 0 # sum of top roc score to later calculate the average of all 5 trials\n",
    "f1_sum = 0 # sum of top accuracy to later calculate the average of all 5 trials\n",
    "accuracy_scores = []\n",
    "roc_scores = []\n",
    "f1_scores = []\n",
    "all_accuracy_models = []\n",
    "all_roc_models = []\n",
    "all_f1_models = []\n",
    "\n",
    "# for every trial\n",
    "for trial in [XY_train1, XY_train2, XY_train3, XY_train4, XY_train5]:\n",
    " \n",
    "    trialnum = trialnum + 1\n",
    "    X_l = trial.drop(['Y'],1)\n",
    "    y_l = trial['Y']\n",
    "    \n",
    "    # Create grid search \n",
    "#     clf = GridSearchCV(pipe, search_space, cv=StratifiedKFold(n_splits=5), \n",
    "#                        scoring=['accuracy', 'roc_auc_ovr', 'f1_micro'], refit=False,\n",
    "#                        verbose=0)\n",
    "    clf = GridSearchCV(KNeighborsClassifier(), param_grid=grid_params, cv=StratifiedKFold(n_splits=5), \n",
    "                      scoring=['accuracy', 'roc_auc_ovr', 'f1_micro'], refit=False, \n",
    "                       n_jobs=-1, verbose=-1)\n",
    "\n",
    "    # Fit grid search\n",
    "    best_model = clf.fit(X_l, y_l)\n",
    "    \n",
    "    print(\"------------------------------------------------------------------------------------\")\n",
    "    print(\"RESULTS FOR TRIAL:\")\n",
    "    print(trialnum)\n",
    "    print(\"------------------------------------------------------------------------------------\")\n",
    "    \n",
    "    # the detailed results of the whole model selection search...\n",
    "#     print(best_model.cv_results_)\n",
    "\n",
    "    print(\"---------------BEST MODEL FOR ACCURACY: ----------\")\n",
    "    print( best_model.cv_results_['params'][ np.argmin(best_model.cv_results_['rank_test_accuracy']) ] )\n",
    "    print(\"---WITH ACCURACY: ---\")\n",
    "    current_accuracy = best_model.cv_results_['mean_test_accuracy'][ np.argmax(best_model.cv_results_['mean_test_accuracy']) ]\n",
    "    print(current_accuracy)\n",
    "    accuracy_sum = accuracy_sum + current_accuracy\n",
    "    accuracy_scores.append(current_accuracy)\n",
    "    all_accuracy_models.append( best_model.cv_results_['params'][ np.argmin(best_model.cv_results_['rank_test_accuracy']) ] )\n",
    "    \n",
    "    print(\"---------------BEST MODEL FOR ROC: ---------------\")\n",
    "    print( best_model.cv_results_['params'][ np.argmin(best_model.cv_results_['rank_test_roc_auc_ovr']) ] )\n",
    "    print(\"---WITH ROC: ---\")\n",
    "    current_roc = best_model.cv_results_['mean_test_roc_auc_ovr'][ np.argmax(best_model.cv_results_['mean_test_roc_auc_ovr']) ]\n",
    "    print(current_roc)\n",
    "    roc_sum = roc_sum + current_roc\n",
    "    roc_scores.append(current_roc)\n",
    "    all_roc_models.append( best_model.cv_results_['params'][ np.argmin(best_model.cv_results_['rank_test_roc_auc_ovr']) ] )\n",
    "\n",
    "    \n",
    "    print(\"---------------BEST MODEL FOR F1: ----------------\")\n",
    "    print( best_model.cv_results_['params'][ np.argmin(best_model.cv_results_['rank_test_f1_micro']) ] )\n",
    "    print(\"---WITH F1: ---\")    \n",
    "    current_f1 = best_model.cv_results_['mean_test_f1_micro'][ np.argmax(best_model.cv_results_['mean_test_f1_micro']) ]\n",
    "    print(current_f1)\n",
    "    f1_sum = f1_sum + current_f1\n",
    "    f1_scores.append(current_f1)\n",
    "    all_f1_models.append( best_model.cv_results_['params'][ np.argmin(best_model.cv_results_['rank_test_f1_micro']) ] )\n",
    "\n",
    "    \n",
    "    # below (optional): check that the above outputs actually show best scores\n",
    "\n",
    "#     print results just to check alignment with the above\n",
    "#     results = pd.DataFrame( best_model.cv_results_['params'] ) # parameter settings for best model\n",
    "#     grab the accuracy score resulting from those parameters\n",
    "#     results['score_acc'] = best_model.cv_results_['mean_test_accuracy']\n",
    "#     results['score_roc'] = best_model.cv_results_['mean_test_roc_auc_ovr']\n",
    "#     results['score_f1'] = best_model.cv_results_['mean_test_f1_micro']\n",
    "#     get rid of classifier__XX in columns\n",
    "#     cols = results.columns.to_series().str.split('__').apply(lambda x: x[-1])\n",
    "#     results.columns = cols\n",
    "#     print(results)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get Train Metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "===== ACCURACY SCORES: =====\n",
      "[0.9461999999999999, 0.9521999999999998, 0.9488, 0.9456, 0.9475999999999999]\n",
      "===== ROC SCORES: =====\n",
      "[0.9874878374135492, 0.9885579215200169, 0.9867112980264757, 0.9881638728062573, 0.9893954494840684]\n",
      "===== F1 SCORES: =====\n",
      "[0.9461999999999999, 0.9522, 0.9488, 0.9456, 0.9475999999999999]\n"
     ]
    }
   ],
   "source": [
    "print(\"===== ACCURACY SCORES: =====\")\n",
    "print(accuracy_scores)\n",
    "print(\"===== ROC SCORES: =====\")\n",
    "print(roc_scores)\n",
    "print(\"===== F1 SCORES: =====\")\n",
    "print(f1_scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================ BEST ACCURACY MODEL IN TRAINING: ==================\n",
      "{'metric': 'manhattan', 'n_neighbors': 3, 'weights': 'distance'}\n",
      "WITH ACCURACY:\n",
      "0.9521999999999998\n",
      "================ BEST ROC MODEL IN TRAINING: ==================\n",
      "{'metric': 'manhattan', 'n_neighbors': 5, 'weights': 'distance'}\n",
      "WITH ROC SCORE:\n",
      "0.9893954494840684\n",
      "================ BEST F1 MODEL IN TRAINING: ==================\n",
      "{'metric': 'manhattan', 'n_neighbors': 3, 'weights': 'distance'}\n",
      "WITH F1 SCORE:\n",
      "0.9522\n"
     ]
    }
   ],
   "source": [
    "print(\"================ BEST ACCURACY MODEL IN TRAINING: ==================\")\n",
    "print(all_accuracy_models[ np.argmax(accuracy_scores) ])\n",
    "print(\"WITH ACCURACY:\")\n",
    "print(max(accuracy_scores))\n",
    "print(\"================ BEST ROC MODEL IN TRAINING: ==================\")\n",
    "print(all_roc_models[ np.argmax(roc_scores) ])\n",
    "print(\"WITH ROC SCORE:\")\n",
    "print(max(roc_scores))\n",
    "print(\"================ BEST F1 MODEL IN TRAINING: ==================\")\n",
    "print(all_f1_models[ np.argmax(f1_scores) ])\n",
    "print(\"WITH F1 SCORE:\")\n",
    "print(max(f1_scores))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================ AVERAGE ACCURACY ON TRAIN SET: ==================\n",
      "0.9480799999999998\n",
      "================ AVERAGE ROC SCORE ON TRAIN SET: ==================\n",
      "0.9880632758500735\n",
      "================ AVERAGE F1 SCORE ON TRAIN SET: ==================\n",
      "0.9480799999999998\n"
     ]
    }
   ],
   "source": [
    "print(\"================ AVERAGE ACCURACY ON TRAIN SET: ==================\")\n",
    "print(accuracy_sum / 5)\n",
    "print(\"================ AVERAGE ROC SCORE ON TRAIN SET: ==================\")\n",
    "print(roc_sum / 5)\n",
    "print(\"================ AVERAGE F1 SCORE ON TRAIN SET: ==================\")\n",
    "print(f1_sum / 5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get Test Metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Trial 1</th>\n",
       "      <th>Trial 2</th>\n",
       "      <th>Trial 3</th>\n",
       "      <th>Trial 4</th>\n",
       "      <th>Trial 5</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>acc</th>\n",
       "      <td>0.953533</td>\n",
       "      <td>0.9508</td>\n",
       "      <td>0.953467</td>\n",
       "      <td>0.9526</td>\n",
       "      <td>0.954067</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>roc</th>\n",
       "      <td>0.95358</td>\n",
       "      <td>0.950841</td>\n",
       "      <td>0.953494</td>\n",
       "      <td>0.9526</td>\n",
       "      <td>0.954105</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>f1</th>\n",
       "      <td>0.953536</td>\n",
       "      <td>0.950437</td>\n",
       "      <td>0.95306</td>\n",
       "      <td>0.952691</td>\n",
       "      <td>0.954027</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      Trial 1   Trial 2   Trial 3   Trial 4   Trial 5\n",
       "acc  0.953533    0.9508  0.953467    0.9526  0.954067\n",
       "roc   0.95358  0.950841  0.953494    0.9526  0.954105\n",
       "f1   0.953536  0.950437   0.95306  0.952691  0.954027"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.metrics import f1_score\n",
    "\n",
    "# test performance of model rated as best for accuracy and f1 score on training set\n",
    "performance_AccModel = pd.DataFrame(index=['acc', 'roc', 'f1'], columns=['Trial 1', 'Trial 2', 'Trial 3', 'Trial 4', 'Trial 5'])\n",
    "performance_AccModel\n",
    "\n",
    "# test performance on trial 1 test set\n",
    "clf = KNeighborsClassifier(metric='manhattan', n_neighbors=3, weights='distance').fit(XY_train1.drop(['Y'],1), XY_train1['Y'])\n",
    "pred = clf.predict(XY_test1.drop(['Y'],1))\n",
    "performance_AccModel.loc['acc', 'Trial 1'] = accuracy_score(XY_test1['Y'], pred)\n",
    "performance_AccModel.loc['roc', 'Trial 1'] = roc_auc_score(XY_test1['Y'], pred)\n",
    "performance_AccModel.loc['f1', 'Trial 1'] = f1_score(XY_test1['Y'], pred)\n",
    "\n",
    "# test performance on trial 2 test set\n",
    "clf = KNeighborsClassifier(metric='manhattan', n_neighbors=3, weights='distance').fit(XY_train2.drop(['Y'],1), XY_train2['Y'])\n",
    "pred = clf.predict(XY_test2.drop(['Y'],1))\n",
    "performance_AccModel.loc['acc', 'Trial 2'] = accuracy_score(XY_test2['Y'], pred)\n",
    "performance_AccModel.loc['roc', 'Trial 2'] = roc_auc_score(XY_test2['Y'], pred)\n",
    "performance_AccModel.loc['f1', 'Trial 2'] = f1_score(XY_test2['Y'], pred)\n",
    "\n",
    "# test performance on trial 3 test set\n",
    "clf = KNeighborsClassifier(metric='manhattan', n_neighbors=3, weights='distance').fit(XY_train3.drop(['Y'],1), XY_train3['Y'])\n",
    "pred = clf.predict(XY_test3.drop(['Y'],1))\n",
    "performance_AccModel.loc['acc', 'Trial 3'] = accuracy_score(XY_test3['Y'], pred)\n",
    "performance_AccModel.loc['roc', 'Trial 3'] = roc_auc_score(XY_test3['Y'], pred)\n",
    "performance_AccModel.loc['f1', 'Trial 3'] = f1_score(XY_test3['Y'], pred)\n",
    "\n",
    "# test performance on trial 4 test set\n",
    "clf = KNeighborsClassifier(metric='manhattan', n_neighbors=3, weights='distance').fit(XY_train4.drop(['Y'],1), XY_train4['Y'])\n",
    "pred = clf.predict(XY_test4.drop(['Y'],1))\n",
    "performance_AccModel.loc['acc', 'Trial 4'] = accuracy_score(XY_test4['Y'], pred)\n",
    "performance_AccModel.loc['roc', 'Trial 4'] = roc_auc_score(XY_test4['Y'], pred)\n",
    "performance_AccModel.loc['f1', 'Trial 4'] = f1_score(XY_test4['Y'], pred)\n",
    "\n",
    "# test performance on trial 5 test set\n",
    "clf = KNeighborsClassifier(metric='manhattan', n_neighbors=3, weights='distance').fit(XY_train5.drop(['Y'],1), XY_train5['Y'])\n",
    "pred = clf.predict(XY_test5.drop(['Y'],1))\n",
    "performance_AccModel.loc['acc', 'Trial 5'] = accuracy_score(XY_test5['Y'], pred)\n",
    "performance_AccModel.loc['roc', 'Trial 5'] = roc_auc_score(XY_test5['Y'], pred)\n",
    "performance_AccModel.loc['f1', 'Trial 5'] = f1_score(XY_test5['Y'], pred)\n",
    "\n",
    "performance_AccModel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Trial 1</th>\n",
       "      <th>Trial 2</th>\n",
       "      <th>Trial 3</th>\n",
       "      <th>Trial 4</th>\n",
       "      <th>Trial 5</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>acc</th>\n",
       "      <td>0.952133</td>\n",
       "      <td>0.949933</td>\n",
       "      <td>0.9518</td>\n",
       "      <td>0.9512</td>\n",
       "      <td>0.950867</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>roc</th>\n",
       "      <td>0.952201</td>\n",
       "      <td>0.950022</td>\n",
       "      <td>0.951873</td>\n",
       "      <td>0.9512</td>\n",
       "      <td>0.950922</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>f1</th>\n",
       "      <td>0.952286</td>\n",
       "      <td>0.949776</td>\n",
       "      <td>0.951571</td>\n",
       "      <td>0.951265</td>\n",
       "      <td>0.950948</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      Trial 1   Trial 2   Trial 3   Trial 4   Trial 5\n",
       "acc  0.952133  0.949933    0.9518    0.9512  0.950867\n",
       "roc  0.952201  0.950022  0.951873    0.9512  0.950922\n",
       "f1   0.952286  0.949776  0.951571  0.951265  0.950948"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# test performance of model rated as best for roc on training set\n",
    "performance_ROCModel = pd.DataFrame(index=['acc', 'roc', 'f1'], columns=['Trial 1', 'Trial 2', 'Trial 3', 'Trial 4', 'Trial 5'])\n",
    "\n",
    "# test performance on trial 1 test set\n",
    "clf = KNeighborsClassifier(metric='manhattan', n_neighbors=5, weights='distance').fit(XY_train1.drop(['Y'],1), XY_train1['Y'])\n",
    "pred = clf.predict(XY_test1.drop(['Y'],1))\n",
    "performance_ROCModel.loc['acc', 'Trial 1'] = accuracy_score(XY_test1['Y'], pred)\n",
    "performance_ROCModel.loc['roc', 'Trial 1'] = roc_auc_score(XY_test1['Y'], pred)\n",
    "performance_ROCModel.loc['f1', 'Trial 1'] = f1_score(XY_test1['Y'], pred)\n",
    "\n",
    "# test performance on trial 2 test set\n",
    "clf = KNeighborsClassifier(metric='manhattan', n_neighbors=5, weights='distance').fit(XY_train2.drop(['Y'],1), XY_train2['Y'])\n",
    "pred = clf.predict(XY_test2.drop(['Y'],1))\n",
    "performance_ROCModel.loc['acc', 'Trial 2'] = accuracy_score(XY_test2['Y'], pred)\n",
    "performance_ROCModel.loc['roc', 'Trial 2'] = roc_auc_score(XY_test2['Y'], pred)\n",
    "performance_ROCModel.loc['f1', 'Trial 2'] = f1_score(XY_test2['Y'], pred)\n",
    "\n",
    "# test performance on trial 3 test set\n",
    "clf = KNeighborsClassifier(metric='manhattan', n_neighbors=5, weights='distance').fit(XY_train3.drop(['Y'],1), XY_train3['Y'])\n",
    "pred = clf.predict(XY_test3.drop(['Y'],1))\n",
    "performance_ROCModel.loc['acc', 'Trial 3'] = accuracy_score(XY_test3['Y'], pred)\n",
    "performance_ROCModel.loc['roc', 'Trial 3'] = roc_auc_score(XY_test3['Y'], pred)\n",
    "performance_ROCModel.loc['f1', 'Trial 3'] = f1_score(XY_test3['Y'], pred)\n",
    "\n",
    "# test performance on trial 4 test set\n",
    "clf = KNeighborsClassifier(metric='manhattan', n_neighbors=5, weights='distance').fit(XY_train4.drop(['Y'],1), XY_train4['Y'])\n",
    "pred = clf.predict(XY_test4.drop(['Y'],1))\n",
    "performance_ROCModel.loc['acc', 'Trial 4'] = accuracy_score(XY_test4['Y'], pred)\n",
    "performance_ROCModel.loc['roc', 'Trial 4'] = roc_auc_score(XY_test4['Y'], pred)\n",
    "performance_ROCModel.loc['f1', 'Trial 4'] = f1_score(XY_test4['Y'], pred)\n",
    "\n",
    "# test performance on trial 5 test set\n",
    "clf = KNeighborsClassifier(metric='manhattan', n_neighbors=5, weights='distance').fit(XY_train5.drop(['Y'],1), XY_train5['Y'])\n",
    "pred = clf.predict(XY_test5.drop(['Y'],1))\n",
    "performance_ROCModel.loc['acc', 'Trial 5'] = accuracy_score(XY_test5['Y'], pred)\n",
    "performance_ROCModel.loc['roc', 'Trial 5'] = roc_auc_score(XY_test5['Y'], pred)\n",
    "performance_ROCModel.loc['f1', 'Trial 5'] = f1_score(XY_test5['Y'], pred)\n",
    "\n",
    "performance_ROCModel"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get final KNN results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================ BEST ACCURACY MODEL IN KNN: ==================\n",
      "{'metric': 'manhattan', 'n_neighbors': 3, 'weights': 'distance'}\n",
      "WITH ACCURACY:\n",
      "0.9528933333333333\n",
      "================ BEST ROC MODEL IN KNN: ==================\n",
      "{'metric': 'manhattan', 'n_neighbors': 5, 'weights': 'distance'}\n",
      "WITH ROC SCORE:\n",
      "0.9512436942161152\n",
      "================ BEST F1 MODEL IN KNN: ==================\n",
      "{'metric': 'manhattan', 'n_neighbors': 3, 'weights': 'distance'}\n",
      "WITH F1 SCORE:\n",
      "0.9527502207921407\n"
     ]
    }
   ],
   "source": [
    "print(\"================ BEST ACCURACY MODEL IN KNN: ==================\")\n",
    "print(all_accuracy_models[ np.argmax(np.array(performance_AccModel.iloc[0])) ])\n",
    "print(\"WITH ACCURACY:\")\n",
    "print((np.array(performance_AccModel.iloc[0])).mean())\n",
    "print(\"================ BEST ROC MODEL IN KNN: ==================\")\n",
    "print(all_roc_models[ np.argmax(np.array(performance_ROCModel.iloc[1])) ])\n",
    "print(\"WITH ROC SCORE:\")\n",
    "print((performance_ROCModel.iloc[1]).mean())\n",
    "print(\"================ BEST F1 MODEL IN KNN: ==================\")\n",
    "print(all_f1_models[ np.argmax(np.array(performance_AccModel.iloc[2])) ])\n",
    "print(\"WITH F1 SCORE:\")\n",
    "print((np.array(performance_AccModel.iloc[2])).mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
