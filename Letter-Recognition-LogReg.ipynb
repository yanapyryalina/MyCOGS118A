{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%config InlineBackend.figure_format = 'retina'\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Format Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>letter</th>\n",
       "      <th>x-box</th>\n",
       "      <th>y-box</th>\n",
       "      <th>width</th>\n",
       "      <th>height</th>\n",
       "      <th>totpix</th>\n",
       "      <th>x-bar</th>\n",
       "      <th>y-bar</th>\n",
       "      <th>x2bar</th>\n",
       "      <th>y2bar</th>\n",
       "      <th>xybar</th>\n",
       "      <th>x2ybar</th>\n",
       "      <th>xy2bar</th>\n",
       "      <th>x-edge</th>\n",
       "      <th>x-edge-y</th>\n",
       "      <th>y-edge</th>\n",
       "      <th>y-edge-x</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>A</td>\n",
       "      <td>4</td>\n",
       "      <td>9</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>2</td>\n",
       "      <td>9</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>8</td>\n",
       "      <td>1</td>\n",
       "      <td>8</td>\n",
       "      <td>2</td>\n",
       "      <td>7</td>\n",
       "      <td>2</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>A</td>\n",
       "      <td>3</td>\n",
       "      <td>6</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>8</td>\n",
       "      <td>2</td>\n",
       "      <td>7</td>\n",
       "      <td>2</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>A</td>\n",
       "      <td>5</td>\n",
       "      <td>9</td>\n",
       "      <td>6</td>\n",
       "      <td>7</td>\n",
       "      <td>7</td>\n",
       "      <td>8</td>\n",
       "      <td>8</td>\n",
       "      <td>8</td>\n",
       "      <td>4</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>8</td>\n",
       "      <td>3</td>\n",
       "      <td>8</td>\n",
       "      <td>8</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>A</td>\n",
       "      <td>4</td>\n",
       "      <td>10</td>\n",
       "      <td>7</td>\n",
       "      <td>7</td>\n",
       "      <td>5</td>\n",
       "      <td>7</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>6</td>\n",
       "      <td>3</td>\n",
       "      <td>7</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>A</td>\n",
       "      <td>4</td>\n",
       "      <td>9</td>\n",
       "      <td>7</td>\n",
       "      <td>7</td>\n",
       "      <td>5</td>\n",
       "      <td>8</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  letter  x-box  y-box  width  height  totpix  x-bar  y-bar  x2bar  y2bar  \\\n",
       "0      A      4      9      6       6       2      9      5      3      1   \n",
       "1      A      3      6      5       4       1      7      5      3      1   \n",
       "2      A      5      9      6       7       7      8      8      8      4   \n",
       "3      A      4     10      7       7       5      7      5      2      3   \n",
       "4      A      4      9      7       7       5      8      5      2      4   \n",
       "\n",
       "   xybar  x2ybar  xy2bar  x-edge  x-edge-y  y-edge  y-edge-x  \n",
       "0      8       1       8       2         7       2         8  \n",
       "1      6       1       8       2         7       2         7  \n",
       "2      6       6       8       3         8       8         4  \n",
       "3      5       2       6       3         7       4         4  \n",
       "4      6       1       5       3         5       4         5  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "header = ['letter', 'x-box', 'y-box', 'width', 'height', 'totpix', \n",
    "         'x-bar', 'y-bar', 'x2bar', 'y2bar', 'xybar', 'x2ybar', 'xy2bar',\n",
    "         'x-edge', 'x-edge-y', 'y-edge', 'y-edge-x']\n",
    "letters = pd.read_csv('https://archive.ics.uci.edu/ml/machine-learning-databases/letter-recognition/letter-recognition.data', names=header)\n",
    "# letters = letters.set_index('letter') \n",
    "letters = letters.sort_values('letter') # order rows alphabetically\n",
    "letters = letters.reset_index(drop=True)\n",
    "letters.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(20000,)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>x-box</th>\n",
       "      <th>y-box</th>\n",
       "      <th>width</th>\n",
       "      <th>height</th>\n",
       "      <th>totpix</th>\n",
       "      <th>x-bar</th>\n",
       "      <th>y-bar</th>\n",
       "      <th>x2bar</th>\n",
       "      <th>y2bar</th>\n",
       "      <th>xybar</th>\n",
       "      <th>x2ybar</th>\n",
       "      <th>xy2bar</th>\n",
       "      <th>x-edge</th>\n",
       "      <th>x-edge-y</th>\n",
       "      <th>y-edge</th>\n",
       "      <th>y-edge-x</th>\n",
       "      <th>Y</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>4</td>\n",
       "      <td>9</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>2</td>\n",
       "      <td>9</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>8</td>\n",
       "      <td>1</td>\n",
       "      <td>8</td>\n",
       "      <td>2</td>\n",
       "      <td>7</td>\n",
       "      <td>2</td>\n",
       "      <td>8</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3</td>\n",
       "      <td>6</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>8</td>\n",
       "      <td>2</td>\n",
       "      <td>7</td>\n",
       "      <td>2</td>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5</td>\n",
       "      <td>9</td>\n",
       "      <td>6</td>\n",
       "      <td>7</td>\n",
       "      <td>7</td>\n",
       "      <td>8</td>\n",
       "      <td>8</td>\n",
       "      <td>8</td>\n",
       "      <td>4</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>8</td>\n",
       "      <td>3</td>\n",
       "      <td>8</td>\n",
       "      <td>8</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>10</td>\n",
       "      <td>7</td>\n",
       "      <td>7</td>\n",
       "      <td>5</td>\n",
       "      <td>7</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>6</td>\n",
       "      <td>3</td>\n",
       "      <td>7</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>9</td>\n",
       "      <td>7</td>\n",
       "      <td>7</td>\n",
       "      <td>5</td>\n",
       "      <td>8</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   x-box  y-box  width  height  totpix  x-bar  y-bar  x2bar  y2bar  xybar  \\\n",
       "0      4      9      6       6       2      9      5      3      1      8   \n",
       "1      3      6      5       4       1      7      5      3      1      6   \n",
       "2      5      9      6       7       7      8      8      8      4      6   \n",
       "3      4     10      7       7       5      7      5      2      3      5   \n",
       "4      4      9      7       7       5      8      5      2      4      6   \n",
       "\n",
       "   x2ybar  xy2bar  x-edge  x-edge-y  y-edge  y-edge-x  Y  \n",
       "0       1       8       2         7       2         8  1  \n",
       "1       1       8       2         7       2         7  1  \n",
       "2       6       8       3         8       8         4  1  \n",
       "3       2       6       3         7       4         4  1  \n",
       "4       1       5       3         5       4         5  1  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# make Y \n",
    "ones_pos = [1]*9940 # 9940 is the number of datapoints with letters A-M\n",
    "ones_neg = [-1]*(20000-9940) # the number of the rest of the datapoints with letters N-Z\n",
    "Y = np.array(ones_pos + ones_neg)\n",
    "print(Y.shape)\n",
    "# make X_and_Y\n",
    "letters_withY = letters\n",
    "letters_withY['Y'] = Y\n",
    "# letters_withY\n",
    "X_and_Y = letters_withY.drop('letter',1)\n",
    "X_and_Y.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create 5 Trials - Training and Testing Sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "XY_train1, XY_test1 = train_test_split(X_and_Y, test_size=15000, shuffle=True)\n",
    "XY_train2, XY_test2 = train_test_split(X_and_Y, test_size=15000, shuffle=True)\n",
    "XY_train3, XY_test3 = train_test_split(X_and_Y, test_size=15000, shuffle=True)\n",
    "XY_train4, XY_test4 = train_test_split(X_and_Y, test_size=15000, shuffle=True)\n",
    "XY_train5, XY_test5 = train_test_split(X_and_Y, test_size=15000, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5000, 17)\n",
      "(15000, 17)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>x-box</th>\n",
       "      <th>y-box</th>\n",
       "      <th>width</th>\n",
       "      <th>height</th>\n",
       "      <th>totpix</th>\n",
       "      <th>x-bar</th>\n",
       "      <th>y-bar</th>\n",
       "      <th>x2bar</th>\n",
       "      <th>y2bar</th>\n",
       "      <th>xybar</th>\n",
       "      <th>x2ybar</th>\n",
       "      <th>xy2bar</th>\n",
       "      <th>x-edge</th>\n",
       "      <th>x-edge-y</th>\n",
       "      <th>y-edge</th>\n",
       "      <th>y-edge-x</th>\n",
       "      <th>Y</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>4687</th>\n",
       "      <td>3</td>\n",
       "      <td>9</td>\n",
       "      <td>5</td>\n",
       "      <td>6</td>\n",
       "      <td>4</td>\n",
       "      <td>7</td>\n",
       "      <td>6</td>\n",
       "      <td>7</td>\n",
       "      <td>5</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>8</td>\n",
       "      <td>2</td>\n",
       "      <td>7</td>\n",
       "      <td>5</td>\n",
       "      <td>11</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3055</th>\n",
       "      <td>6</td>\n",
       "      <td>10</td>\n",
       "      <td>6</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>8</td>\n",
       "      <td>6</td>\n",
       "      <td>5</td>\n",
       "      <td>6</td>\n",
       "      <td>12</td>\n",
       "      <td>4</td>\n",
       "      <td>7</td>\n",
       "      <td>5</td>\n",
       "      <td>7</td>\n",
       "      <td>5</td>\n",
       "      <td>9</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17615</th>\n",
       "      <td>5</td>\n",
       "      <td>6</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>11</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "      <td>8</td>\n",
       "      <td>5</td>\n",
       "      <td>11</td>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18047</th>\n",
       "      <td>3</td>\n",
       "      <td>9</td>\n",
       "      <td>4</td>\n",
       "      <td>7</td>\n",
       "      <td>3</td>\n",
       "      <td>8</td>\n",
       "      <td>7</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>7</td>\n",
       "      <td>6</td>\n",
       "      <td>9</td>\n",
       "      <td>2</td>\n",
       "      <td>8</td>\n",
       "      <td>4</td>\n",
       "      <td>8</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18231</th>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>10</td>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "      <td>8</td>\n",
       "      <td>11</td>\n",
       "      <td>3</td>\n",
       "      <td>7</td>\n",
       "      <td>2</td>\n",
       "      <td>8</td>\n",
       "      <td>3</td>\n",
       "      <td>9</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       x-box  y-box  width  height  totpix  x-bar  y-bar  x2bar  y2bar  xybar  \\\n",
       "4687       3      9      5       6       4      7      6      7      5      6   \n",
       "3055       6     10      6       5       3      8      6      5      6     12   \n",
       "17615      5      6      5       4       4      2     11      2      3     10   \n",
       "18047      3      9      4       7       3      8      7      4      4      7   \n",
       "18231      3      5      5       4       2     10      7      1      8     11   \n",
       "\n",
       "       x2ybar  xy2bar  x-edge  x-edge-y  y-edge  y-edge-x  Y  \n",
       "4687        6       8       2         7       5        11  1  \n",
       "3055        4       7       5         7       5         9  1  \n",
       "17615      10       8       5        11       1         7 -1  \n",
       "18047       6       9       2         8       4         8 -1  \n",
       "18231       3       7       2         8       3         9 -1  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(XY_train1.shape)\n",
    "print(XY_test1.shape)\n",
    "XY_train1.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------------------------------------------------------\n",
      "RESULTS FOR TRIAL:\n",
      "1\n",
      "------------------------------------------------------------------------------------\n",
      "---------------BEST MODEL FOR ACCURACY: ----------\n",
      "{'classifier': LogisticRegression(max_iter=10000), 'classifier__C': 177.82794100389228, 'classifier__penalty': 'l1', 'classifier__solver': 'saga'}\n",
      "---WITH ACCURACY: ---\n",
      "0.7213999999999999\n",
      "---------------BEST MODEL FOR ROC: ---------------\n",
      "{'classifier': LogisticRegression(max_iter=10000), 'classifier__C': 31622.776601683792, 'classifier__penalty': 'l1', 'classifier__solver': 'saga'}\n",
      "---WITH ROC: ---\n",
      "0.8099302224184749\n",
      "---------------BEST MODEL FOR F1: ----------------\n",
      "{'classifier': LogisticRegression(max_iter=10000), 'classifier__C': 177.82794100389228, 'classifier__penalty': 'l1', 'classifier__solver': 'saga'}\n",
      "---WITH F1: ---\n",
      "0.7213999999999999\n",
      "------------------------------------------------------------------------------------\n",
      "RESULTS FOR TRIAL:\n",
      "2\n",
      "------------------------------------------------------------------------------------\n",
      "---------------BEST MODEL FOR ACCURACY: ----------\n",
      "{'classifier': LogisticRegression(max_iter=10000), 'classifier__C': 177.82794100389228, 'classifier__penalty': 'l1', 'classifier__solver': 'saga'}\n",
      "---WITH ACCURACY: ---\n",
      "0.7251999999999998\n",
      "---------------BEST MODEL FOR ROC: ---------------\n",
      "{'classifier': LogisticRegression(max_iter=10000), 'classifier__C': 5623413.251903491, 'classifier__penalty': 'l1', 'classifier__solver': 'saga'}\n",
      "---WITH ROC: ---\n",
      "0.8057376744326238\n",
      "---------------BEST MODEL FOR F1: ----------------\n",
      "{'classifier': LogisticRegression(max_iter=10000), 'classifier__C': 177.82794100389228, 'classifier__penalty': 'l1', 'classifier__solver': 'saga'}\n",
      "---WITH F1: ---\n",
      "0.7251999999999998\n",
      "------------------------------------------------------------------------------------\n",
      "RESULTS FOR TRIAL:\n",
      "3\n",
      "------------------------------------------------------------------------------------\n",
      "---------------BEST MODEL FOR ACCURACY: ----------\n",
      "{'classifier': LogisticRegression(max_iter=10000), 'classifier__C': 1.0, 'classifier__penalty': 'l2', 'classifier__solver': 'saga'}\n",
      "---WITH ACCURACY: ---\n",
      "0.7178\n",
      "---------------BEST MODEL FOR ROC: ---------------\n",
      "{'classifier': LogisticRegression(max_iter=10000), 'classifier__penalty': 'none', 'classifier__solver': 'saga'}\n",
      "---WITH ROC: ---\n",
      "0.8062200765400075\n",
      "---------------BEST MODEL FOR F1: ----------------\n",
      "{'classifier': LogisticRegression(max_iter=10000), 'classifier__C': 177.82794100389228, 'classifier__penalty': 'l1', 'classifier__solver': 'saga'}\n",
      "---WITH F1: ---\n",
      "0.7178\n",
      "------------------------------------------------------------------------------------\n",
      "RESULTS FOR TRIAL:\n",
      "4\n",
      "------------------------------------------------------------------------------------\n",
      "---------------BEST MODEL FOR ACCURACY: ----------\n",
      "{'classifier': LogisticRegression(max_iter=10000), 'classifier__C': 1.0, 'classifier__penalty': 'l2', 'classifier__solver': 'saga'}\n",
      "---WITH ACCURACY: ---\n",
      "0.733\n",
      "---------------BEST MODEL FOR ROC: ---------------\n",
      "{'classifier': LogisticRegression(max_iter=10000), 'classifier__C': 1000000000.0, 'classifier__penalty': 'l1', 'classifier__solver': 'saga'}\n",
      "---WITH ROC: ---\n",
      "0.8217347737806951\n",
      "---------------BEST MODEL FOR F1: ----------------\n",
      "{'classifier': LogisticRegression(max_iter=10000), 'classifier__C': 1.0, 'classifier__penalty': 'l2', 'classifier__solver': 'saga'}\n",
      "---WITH F1: ---\n",
      "0.733\n",
      "------------------------------------------------------------------------------------\n",
      "RESULTS FOR TRIAL:\n",
      "5\n",
      "------------------------------------------------------------------------------------\n",
      "---------------BEST MODEL FOR ACCURACY: ----------\n",
      "{'classifier': LogisticRegression(max_iter=10000), 'classifier__C': 177.82794100389228, 'classifier__penalty': 'l2', 'classifier__solver': 'saga'}\n",
      "---WITH ACCURACY: ---\n",
      "0.735\n",
      "---------------BEST MODEL FOR ROC: ---------------\n",
      "{'classifier': LogisticRegression(max_iter=10000), 'classifier__C': 1000000000.0, 'classifier__penalty': 'l2', 'classifier__solver': 'saga'}\n",
      "---WITH ROC: ---\n",
      "0.8234107724782899\n",
      "---------------BEST MODEL FOR F1: ----------------\n",
      "{'classifier': LogisticRegression(max_iter=10000), 'classifier__C': 177.82794100389228, 'classifier__penalty': 'l2', 'classifier__solver': 'saga'}\n",
      "---WITH F1: ---\n",
      "0.735\n",
      "Wall time: 28.1 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "#import warnings\n",
    "# there are a lot of convergence warnings for some params, however be careful with this!!\n",
    "# sometimes you need to see those wanrings, and now we've screwed tha tup for the whole notebook from here on!!\n",
    "#warnings.filterwarnings('ignore')\n",
    "\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn import datasets\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.linear_model import LogisticRegression \n",
    "import numpy as np\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "# Create a pipeline - RF is a stand in, we will populate the classifier part below\n",
    "pipe = Pipeline([('std', StandardScaler()),\n",
    "                 ('classifier', LogisticRegression())])\n",
    "\n",
    "# Create search space of candidate learning algorithms and their hyperparameters\n",
    "# note lbfgs can't do l1, and if you pass penalty='none' it expects no C value\n",
    "search_space = [{'classifier': [LogisticRegression(max_iter=10000)],\n",
    "                 'classifier__solver': ['saga'],\n",
    "                 'classifier__penalty': ['l1', 'l2'],\n",
    "                 'classifier__C': np.logspace(-9, 9, 9)},\n",
    "                {'classifier': [LogisticRegression(max_iter=10000)],\n",
    "                 'classifier__solver': ['lbfgs'],\n",
    "                 'classifier__penalty': ['l2'],\n",
    "                 'classifier__C': np.logspace(-9, 9, 9)},\n",
    "                {'classifier': [LogisticRegression(max_iter=10000)],\n",
    "                 'classifier__solver': ['lbfgs','saga'],\n",
    "                 'classifier__penalty': ['none']}\n",
    "                ]\n",
    "\n",
    "trialnum = 0\n",
    "accuracy_sum = 0 # sum of top accuracy to later calculate the average of all 5 trials\n",
    "roc_sum = 0 # sum of top roc score to later calculate the average of all 5 trials\n",
    "f1_sum = 0 # sum of top accuracy to later calculate the average of all 5 trials\n",
    "accuracy_scores = []\n",
    "roc_scores = []\n",
    "f1_scores = []\n",
    "all_accuracy_models = []\n",
    "all_roc_models = []\n",
    "all_f1_models = []\n",
    "\n",
    "# for every trial\n",
    "for trial in [XY_train1, XY_train2, XY_train3, XY_train4, XY_train5]:\n",
    " \n",
    "    trialnum = trialnum + 1\n",
    "    X_l = trial.drop(['Y'],1)\n",
    "    y_l = trial['Y']\n",
    "    \n",
    "    # Create grid search \n",
    "    clf = GridSearchCV(pipe, search_space, cv=StratifiedKFold(n_splits=5), \n",
    "                       scoring=['accuracy', 'roc_auc_ovr', 'f1_micro'], refit=False,\n",
    "                       verbose=0)\n",
    "\n",
    "    # Fit grid search\n",
    "    best_model = clf.fit(X_l, y_l)\n",
    "    \n",
    "    print(\"------------------------------------------------------------------------------------\")\n",
    "    print(\"RESULTS FOR TRIAL:\")\n",
    "    print(trialnum)\n",
    "    print(\"------------------------------------------------------------------------------------\")\n",
    "    \n",
    "    # the detailed results of the whole model selection search...\n",
    "#     print(best_model.cv_results_)\n",
    "\n",
    "    print(\"---------------BEST MODEL FOR ACCURACY: ----------\")\n",
    "    print( best_model.cv_results_['params'][ np.argmin(best_model.cv_results_['rank_test_accuracy']) ] )\n",
    "    print(\"---WITH ACCURACY: ---\")\n",
    "    current_accuracy = best_model.cv_results_['mean_test_accuracy'][ np.argmax(best_model.cv_results_['mean_test_accuracy']) ]\n",
    "    print(current_accuracy)\n",
    "    accuracy_sum = accuracy_sum + current_accuracy\n",
    "    accuracy_scores.append(current_accuracy)\n",
    "    all_accuracy_models.append( best_model.cv_results_['params'][ np.argmin(best_model.cv_results_['rank_test_accuracy']) ] )\n",
    "    \n",
    "    print(\"---------------BEST MODEL FOR ROC: ---------------\")\n",
    "    print( best_model.cv_results_['params'][ np.argmin(best_model.cv_results_['rank_test_roc_auc_ovr']) ] )\n",
    "    print(\"---WITH ROC: ---\")\n",
    "    current_roc = best_model.cv_results_['mean_test_roc_auc_ovr'][ np.argmax(best_model.cv_results_['mean_test_roc_auc_ovr']) ]\n",
    "    print(current_roc)\n",
    "    roc_sum = roc_sum + current_roc\n",
    "    roc_scores.append(current_roc)\n",
    "    all_roc_models.append( best_model.cv_results_['params'][ np.argmin(best_model.cv_results_['rank_test_roc_auc_ovr']) ] )\n",
    "\n",
    "    \n",
    "    print(\"---------------BEST MODEL FOR F1: ----------------\")\n",
    "    print( best_model.cv_results_['params'][ np.argmin(best_model.cv_results_['rank_test_f1_micro']) ] )\n",
    "    print(\"---WITH F1: ---\")    \n",
    "    current_f1 = best_model.cv_results_['mean_test_f1_micro'][ np.argmax(best_model.cv_results_['mean_test_f1_micro']) ]\n",
    "    print(current_f1)\n",
    "    f1_sum = f1_sum + current_f1\n",
    "    f1_scores.append(current_f1)\n",
    "    all_f1_models.append( best_model.cv_results_['params'][ np.argmin(best_model.cv_results_['rank_test_f1_micro']) ] )\n",
    "\n",
    "    \n",
    "    # below (optional): check that the above outputs actually show best scores\n",
    "\n",
    "#     print results just to check alignment with the above\n",
    "#     results = pd.DataFrame( best_model.cv_results_['params'] ) # parameter settings for best model\n",
    "#     grab the accuracy score resulting from those parameters\n",
    "#     results['score_acc'] = best_model.cv_results_['mean_test_accuracy']\n",
    "#     results['score_roc'] = best_model.cv_results_['mean_test_roc_auc_ovr']\n",
    "#     results['score_f1'] = best_model.cv_results_['mean_test_f1_micro']\n",
    "#     get rid of classifier__XX in columns\n",
    "#     cols = results.columns.to_series().str.split('__').apply(lambda x: x[-1])\n",
    "#     results.columns = cols\n",
    "#     print(results)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get Train Metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "===== ACCURACY SCORES: =====\n",
      "[0.7213999999999999, 0.7251999999999998, 0.7178, 0.733, 0.735]\n",
      "===== ROC SCORES: =====\n",
      "[0.8099302224184749, 0.8057376744326238, 0.8062200765400075, 0.8217347737806951, 0.8234107724782899]\n",
      "===== F1 SCORES: =====\n",
      "[0.7213999999999999, 0.7251999999999998, 0.7178, 0.733, 0.735]\n"
     ]
    }
   ],
   "source": [
    "print(\"===== ACCURACY SCORES: =====\")\n",
    "print(accuracy_scores)\n",
    "print(\"===== ROC SCORES: =====\")\n",
    "print(roc_scores)\n",
    "print(\"===== F1 SCORES: =====\")\n",
    "print(f1_scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================ BEST ACCURACY MODEL IN TRAINING: ==================\n",
      "{'classifier': LogisticRegression(max_iter=10000), 'classifier__C': 177.82794100389228, 'classifier__penalty': 'l2', 'classifier__solver': 'saga'}\n",
      "WITH ACCURACY:\n",
      "0.735\n",
      "================ BEST ROC MODEL IN TRAINING: ==================\n",
      "{'classifier': LogisticRegression(max_iter=10000), 'classifier__C': 1000000000.0, 'classifier__penalty': 'l2', 'classifier__solver': 'saga'}\n",
      "WITH ROC SCORE:\n",
      "0.8234107724782899\n",
      "================ BEST F1 MODEL IN TRAINING: ==================\n",
      "{'classifier': LogisticRegression(max_iter=10000), 'classifier__C': 177.82794100389228, 'classifier__penalty': 'l2', 'classifier__solver': 'saga'}\n",
      "WITH F1 SCORE:\n",
      "0.735\n"
     ]
    }
   ],
   "source": [
    "print(\"================ BEST ACCURACY MODEL IN TRAINING: ==================\")\n",
    "print(all_accuracy_models[ np.argmax(accuracy_scores) ])\n",
    "print(\"WITH ACCURACY:\")\n",
    "print(max(accuracy_scores))\n",
    "print(\"================ BEST ROC MODEL IN TRAINING: ==================\")\n",
    "print(all_roc_models[ np.argmax(roc_scores) ])\n",
    "print(\"WITH ROC SCORE:\")\n",
    "print(max(roc_scores))\n",
    "print(\"================ BEST F1 MODEL IN TRAINING: ==================\")\n",
    "print(all_f1_models[ np.argmax(f1_scores) ])\n",
    "print(\"WITH F1 SCORE:\")\n",
    "print(max(f1_scores))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================ AVERAGE ACCURACY ON TRAIN SET: ==================\n",
      "0.7264799999999999\n",
      "================ AVERAGE ROC SCORE ON TRAIN SET: ==================\n",
      "0.8134067039300182\n",
      "================ AVERAGE F1 SCORE ON TRAIN SET: ==================\n",
      "0.7264799999999999\n"
     ]
    }
   ],
   "source": [
    "print(\"================ AVERAGE ACCURACY ON TRAIN SET: ==================\")\n",
    "print(accuracy_sum / 5)\n",
    "print(\"================ AVERAGE ROC SCORE ON TRAIN SET: ==================\")\n",
    "print(roc_sum / 5)\n",
    "print(\"================ AVERAGE F1 SCORE ON TRAIN SET: ==================\")\n",
    "print(f1_sum / 5)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get Test Metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Trial 1</th>\n",
       "      <th>Trial 2</th>\n",
       "      <th>Trial 3</th>\n",
       "      <th>Trial 4</th>\n",
       "      <th>Trial 5</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>acc</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>roc</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>f1</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Trial 1 Trial 2 Trial 3 Trial 4 Trial 5\n",
       "acc     NaN     NaN     NaN     NaN     NaN\n",
       "roc     NaN     NaN     NaN     NaN     NaN\n",
       "f1      NaN     NaN     NaN     NaN     NaN"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "performance_AccModel = pd.DataFrame(index=['acc', 'roc', 'f1'], columns=['Trial 1', 'Trial 2', 'Trial 3', 'Trial 4', 'Trial 5'])\n",
    "performance_AccModel"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Best Training Accuracy & F1 Score Model Results after Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Trial 1</th>\n",
       "      <th>Trial 2</th>\n",
       "      <th>Trial 3</th>\n",
       "      <th>Trial 4</th>\n",
       "      <th>Trial 5</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>acc</th>\n",
       "      <td>0.728267</td>\n",
       "      <td>0.725533</td>\n",
       "      <td>0.7268</td>\n",
       "      <td>0.725733</td>\n",
       "      <td>0.7198</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>roc</th>\n",
       "      <td>0.728314</td>\n",
       "      <td>0.725669</td>\n",
       "      <td>0.726818</td>\n",
       "      <td>0.725864</td>\n",
       "      <td>0.719897</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>f1</th>\n",
       "      <td>0.730566</td>\n",
       "      <td>0.727044</td>\n",
       "      <td>0.72337</td>\n",
       "      <td>0.728305</td>\n",
       "      <td>0.721821</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      Trial 1   Trial 2   Trial 3   Trial 4   Trial 5\n",
       "acc  0.728267  0.725533    0.7268  0.725733    0.7198\n",
       "roc  0.728314  0.725669  0.726818  0.725864  0.719897\n",
       "f1   0.730566  0.727044   0.72337  0.728305  0.721821"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.metrics import f1_score\n",
    "\n",
    "# test performance of model rated as best for accuracy and f1 score on training set\n",
    "\n",
    "# test performance on trial 1 test set\n",
    "clf = LogisticRegression(penalty='l1', C=1.0, solver='saga', max_iter=10000).fit(XY_train1.drop(['Y'],1), XY_train1['Y'])\n",
    "pred = clf.predict(XY_test1.drop(['Y'],1))\n",
    "performance_AccModel.loc['acc', 'Trial 1'] = accuracy_score(XY_test1['Y'], pred)\n",
    "performance_AccModel.loc['roc', 'Trial 1'] = roc_auc_score(XY_test1['Y'], pred)\n",
    "performance_AccModel.loc['f1', 'Trial 1'] = f1_score(XY_test1['Y'], pred)\n",
    "\n",
    "# test performance on trial 2 test set\n",
    "clf = LogisticRegression(penalty='l1', C=1.0, solver='saga', max_iter=10000).fit(XY_train2.drop(['Y'],1), XY_train2['Y'])\n",
    "pred = clf.predict(XY_test2.drop(['Y'],1))\n",
    "performance_AccModel.loc['acc', 'Trial 2'] = accuracy_score(XY_test2['Y'], pred)\n",
    "performance_AccModel.loc['roc', 'Trial 2'] = roc_auc_score(XY_test2['Y'], pred)\n",
    "performance_AccModel.loc['f1', 'Trial 2'] = f1_score(XY_test2['Y'], pred)\n",
    "\n",
    "# test performance on trial 3 test set\n",
    "clf = LogisticRegression(penalty='l1', C=1.0, solver='saga', max_iter=10000).fit(XY_train3.drop(['Y'],1), XY_train3['Y'])\n",
    "pred = clf.predict(XY_test3.drop(['Y'],1))\n",
    "performance_AccModel.loc['acc', 'Trial 3'] = accuracy_score(XY_test3['Y'], pred)\n",
    "performance_AccModel.loc['roc', 'Trial 3'] = roc_auc_score(XY_test3['Y'], pred)\n",
    "performance_AccModel.loc['f1', 'Trial 3'] = f1_score(XY_test3['Y'], pred)\n",
    "\n",
    "# test performance on trial 4 test set\n",
    "clf = LogisticRegression(penalty='l1', C=1.0, solver='saga', max_iter=10000).fit(XY_train4.drop(['Y'],1), XY_train4['Y'])\n",
    "pred = clf.predict(XY_test4.drop(['Y'],1))\n",
    "performance_AccModel.loc['acc', 'Trial 4'] = accuracy_score(XY_test4['Y'], pred)\n",
    "performance_AccModel.loc['roc', 'Trial 4'] = roc_auc_score(XY_test4['Y'], pred)\n",
    "performance_AccModel.loc['f1', 'Trial 4'] = f1_score(XY_test4['Y'], pred)\n",
    "\n",
    "# test performance on trial 5 test set\n",
    "clf = LogisticRegression(penalty='l1', C=1.0, solver='saga', max_iter=10000).fit(XY_train5.drop(['Y'],1), XY_train5['Y'])\n",
    "pred = clf.predict(XY_test5.drop(['Y'],1))\n",
    "performance_AccModel.loc['acc', 'Trial 5'] = accuracy_score(XY_test5['Y'], pred)\n",
    "performance_AccModel.loc['roc', 'Trial 5'] = roc_auc_score(XY_test5['Y'], pred)\n",
    "performance_AccModel.loc['f1', 'Trial 5'] = f1_score(XY_test5['Y'], pred)\n",
    "\n",
    "performance_AccModel"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Best Training ROC Score Model Results after Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Trial 1</th>\n",
       "      <th>Trial 2</th>\n",
       "      <th>Trial 3</th>\n",
       "      <th>Trial 4</th>\n",
       "      <th>Trial 5</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>acc</th>\n",
       "      <td>0.728</td>\n",
       "      <td>0.724667</td>\n",
       "      <td>0.726733</td>\n",
       "      <td>0.725067</td>\n",
       "      <td>0.720133</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>roc</th>\n",
       "      <td>0.728048</td>\n",
       "      <td>0.724807</td>\n",
       "      <td>0.726749</td>\n",
       "      <td>0.725196</td>\n",
       "      <td>0.720232</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>f1</th>\n",
       "      <td>0.730337</td>\n",
       "      <td>0.726309</td>\n",
       "      <td>0.723657</td>\n",
       "      <td>0.727609</td>\n",
       "      <td>0.722208</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      Trial 1   Trial 2   Trial 3   Trial 4   Trial 5\n",
       "acc     0.728  0.724667  0.726733  0.725067  0.720133\n",
       "roc  0.728048  0.724807  0.726749  0.725196  0.720232\n",
       "f1   0.730337  0.726309  0.723657  0.727609  0.722208"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# test performance of model rated as best for roc on training set\n",
    "performance_ROCModel = pd.DataFrame(index=['acc', 'roc', 'f1'], columns=['Trial 1', 'Trial 2', 'Trial 3', 'Trial 4', 'Trial 5'])\n",
    "\n",
    "# test performance on trial 1 test set\n",
    "clf = LogisticRegression(penalty='l2', C=177.82794100389228, solver='lbfgs', max_iter=10000).fit(XY_train1.drop(['Y'],1), XY_train1['Y'])\n",
    "pred = clf.predict(XY_test1.drop(['Y'],1))\n",
    "performance_ROCModel.loc['acc', 'Trial 1'] = accuracy_score(XY_test1['Y'], pred)\n",
    "performance_ROCModel.loc['roc', 'Trial 1'] = roc_auc_score(XY_test1['Y'], pred)\n",
    "performance_ROCModel.loc['f1', 'Trial 1'] = f1_score(XY_test1['Y'], pred)\n",
    "\n",
    "# test performance on trial 2 test set\n",
    "clf = LogisticRegression(penalty='l2', C=177.82794100389228, solver='lbfgs', max_iter=10000).fit(XY_train2.drop(['Y'],1), XY_train2['Y'])\n",
    "pred = clf.predict(XY_test2.drop(['Y'],1))\n",
    "performance_ROCModel.loc['acc', 'Trial 2'] = accuracy_score(XY_test2['Y'], pred)\n",
    "performance_ROCModel.loc['roc', 'Trial 2'] = roc_auc_score(XY_test2['Y'], pred)\n",
    "performance_ROCModel.loc['f1', 'Trial 2'] = f1_score(XY_test2['Y'], pred)\n",
    "\n",
    "# test performance on trial 3 test set\n",
    "clf = LogisticRegression(penalty='l2', C=177.82794100389228, solver='lbfgs', max_iter=10000).fit(XY_train3.drop(['Y'],1), XY_train3['Y'])\n",
    "pred = clf.predict(XY_test3.drop(['Y'],1))\n",
    "performance_ROCModel.loc['acc', 'Trial 3'] = accuracy_score(XY_test3['Y'], pred)\n",
    "performance_ROCModel.loc['roc', 'Trial 3'] = roc_auc_score(XY_test3['Y'], pred)\n",
    "performance_ROCModel.loc['f1', 'Trial 3'] = f1_score(XY_test3['Y'], pred)\n",
    "\n",
    "# test performance on trial 4 test set\n",
    "clf = LogisticRegression(penalty='l2', C=177.82794100389228, solver='lbfgs', max_iter=10000).fit(XY_train4.drop(['Y'],1), XY_train4['Y'])\n",
    "pred = clf.predict(XY_test4.drop(['Y'],1))\n",
    "performance_ROCModel.loc['acc', 'Trial 4'] = accuracy_score(XY_test4['Y'], pred)\n",
    "performance_ROCModel.loc['roc', 'Trial 4'] = roc_auc_score(XY_test4['Y'], pred)\n",
    "performance_ROCModel.loc['f1', 'Trial 4'] = f1_score(XY_test4['Y'], pred)\n",
    "\n",
    "# test performance on trial 5 test set\n",
    "clf = LogisticRegression(penalty='l2', C=177.82794100389228, solver='lbfgs', max_iter=10000).fit(XY_train5.drop(['Y'],1), XY_train5['Y'])\n",
    "pred = clf.predict(XY_test5.drop(['Y'],1))\n",
    "performance_ROCModel.loc['acc', 'Trial 5'] = accuracy_score(XY_test5['Y'], pred)\n",
    "performance_ROCModel.loc['roc', 'Trial 5'] = roc_auc_score(XY_test5['Y'], pred)\n",
    "performance_ROCModel.loc['f1', 'Trial 5'] = f1_score(XY_test5['Y'], pred)\n",
    "\n",
    "performance_ROCModel"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get Final Logistic Regression Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================ BEST ACCURACY MODEL IN LOGISTIC REGRESSION: ==================\n",
      "{'classifier': LogisticRegression(max_iter=10000), 'classifier__C': 177.82794100389228, 'classifier__penalty': 'l1', 'classifier__solver': 'saga'}\n",
      "WITH ACCURACY:\n",
      "0.7252266666666667\n",
      "================ BEST ROC MODEL IN LOGISTIC REGRESSION: ==================\n",
      "{'classifier': LogisticRegression(max_iter=10000), 'classifier__C': 31622.776601683792, 'classifier__penalty': 'l1', 'classifier__solver': 'saga'}\n",
      "WITH ROC SCORE:\n",
      "0.7250066218471684\n",
      "================ BEST F1 MODEL IN LOGISTIC REGRESSION: ==================\n",
      "{'classifier': LogisticRegression(max_iter=10000), 'classifier__C': 177.82794100389228, 'classifier__penalty': 'l1', 'classifier__solver': 'saga'}\n",
      "WITH F1 SCORE:\n",
      "0.7262212243607072\n"
     ]
    }
   ],
   "source": [
    "print(\"================ BEST ACCURACY MODEL IN LOGISTIC REGRESSION: ==================\")\n",
    "print(all_accuracy_models[ np.argmax(np.array(performance_AccModel.iloc[0])) ])\n",
    "print(\"WITH ACCURACY:\")\n",
    "print((np.array(performance_AccModel.iloc[0])).mean())\n",
    "print(\"================ BEST ROC MODEL IN LOGISTIC REGRESSION: ==================\")\n",
    "print(all_roc_models[ np.argmax(np.array(performance_ROCModel.iloc[1])) ])\n",
    "print(\"WITH ROC SCORE:\")\n",
    "print((performance_ROCModel.iloc[1]).mean())\n",
    "print(\"================ BEST F1 MODEL IN LOGISTIC REGRESSION: ==================\")\n",
    "print(all_f1_models[ np.argmax(np.array(performance_AccModel.iloc[2])) ])\n",
    "print(\"WITH F1 SCORE:\")\n",
    "print((np.array(performance_AccModel.iloc[2])).mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
